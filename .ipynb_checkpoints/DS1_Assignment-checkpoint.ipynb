{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a294ca1f-c0f5-44c8-b6c5-db4ee4b59090",
   "metadata": {},
   "source": [
    "# <center> Data Science 1 - Final Assignment <center>\n",
    "<center>Created by Zsófia Rebeka Katona<center>\n",
    "\n",
    "    ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098216e-d606-43a8-bbba-552ab40a3245",
   "metadata": {},
   "source": [
    "The goal of this assignment is to explore the concepts of ridge regression and principal component analysis (PCA) in the context of predictive modeling. We'll examine two exercises:\n",
    "\n",
    "1. Ridge Regression Analysis:\n",
    "\n",
    "- We begin by considering a simple predictive model where the response variable is predicted using only a constant term. We then introduce ridge regression, which is a regularized version of linear regression, and compare its performance with ordinary least squares (OLS) regression.\n",
    "- We generate a sample dataset with a known true parameter and noise distribution. Using this dataset, we compute ridge regression estimates for various values of the regularization parameter lambda (λ) and analyze the bias, variance, and mean squared error (MSE) of these estimates.\n",
    "- Finally, we plot the bias, variance, and MSE as functions of lambda to interpret the results and determine whether ridge regression provides better predictions than OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898052d9-729c-4180-be4a-946c56f10173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978c1df-4211-455b-adb9-0879ea8aeb3c",
   "metadata": {},
   "source": [
    "## 1. Ridge Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4551be9-3098-4d53-9189-06a5d4dbc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OLS Estimator is 2.0127181593375885\n",
      "The Ridge Estimator is 1.750189703771816, when lambda is 3.0\n"
     ]
    }
   ],
   "source": [
    "# Setting the random seed\n",
    "np.random.seed(20240315)\n",
    "\n",
    "# Settings\n",
    "n = 20\n",
    "sigma = 1.0\n",
    "beta_zero = 2\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma, size = n)\n",
    "Y = beta_zero + epsilon\n",
    "\n",
    "# Creating the estimator for the OLS model\n",
    "beta_ols = np.mean(Y)\n",
    "\n",
    "# Define the Ridge Estimator functrion\n",
    "def ridge_estimator(n, alpha):\n",
    "    n = len(Y)\n",
    "    return np.sum(Y)/(n + alpha)\n",
    "\n",
    "# Define a nonzero lambda\n",
    "alpha_ridge = 3.0\n",
    "\n",
    "# Calculating the Ridge Estimator\n",
    "beta_ridge = ridge_estimator(n, alpha_ridge)\n",
    "\n",
    "# Comparing the two values\n",
    "print(f\"The OLS Estimator is {beta_ols}\")\n",
    "print(f\"The Ridge Estimator is {beta_ridge}, when lambda is {alpha_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1c770-a105-4f6f-bbc6-46b3bd7e2541",
   "metadata": {},
   "source": [
    "#### a, How does the regularized estimator (predictor) βˆridge compare with the OLS estimator?\n",
    "- The Ridge Estimator is expected to be smaller as we apply a penalty term and the coefficient will be be smaller. \n",
    "- The penalty term shrinks the coefficients close to 0. Introducing a penalty term results in a shinkrage effect on the coefficient estimates.\n",
    "- The higher the penalty term, the more the coefficients shrink towards 0.\n",
    "\n",
    "#### b, Suppose that β0 = 1 and ϵ ∼ N(0, σ2) with σ2 = 4. Generate a sample of size n = 20 from the model and compute the predicted value Yˆ = ˆf(x) = βˆridge 0 for a grid of λ values over the interval [0, 20]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2405fed6-0534-4d2b-92e2-743f51cda28f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphas</th>\n",
       "      <th>Estimated values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.387243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.330404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.276209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.224477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.175044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.127760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2.082489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.039103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.997489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.957539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.919156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.882249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1.846735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.812536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.779581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.747803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>1.717140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.687534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.5</td>\n",
       "      <td>1.658932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.631283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1.604540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.578661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.5</td>\n",
       "      <td>1.553603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.529328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.5</td>\n",
       "      <td>1.505799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.482984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.5</td>\n",
       "      <td>1.460850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.439367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.5</td>\n",
       "      <td>1.418507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.398242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.5</td>\n",
       "      <td>1.378549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.359402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.5</td>\n",
       "      <td>1.340780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.322662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17.5</td>\n",
       "      <td>1.305026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.5</td>\n",
       "      <td>1.271129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.254833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.5</td>\n",
       "      <td>1.238949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alphas  Estimated values\n",
       "0      0.5          2.387243\n",
       "1      1.0          2.330404\n",
       "2      1.5          2.276209\n",
       "3      2.0          2.224477\n",
       "4      2.5          2.175044\n",
       "5      3.0          2.127760\n",
       "6      3.5          2.082489\n",
       "7      4.0          2.039103\n",
       "8      4.5          1.997489\n",
       "9      5.0          1.957539\n",
       "10     5.5          1.919156\n",
       "11     6.0          1.882249\n",
       "12     6.5          1.846735\n",
       "13     7.0          1.812536\n",
       "14     7.5          1.779581\n",
       "15     8.0          1.747803\n",
       "16     8.5          1.717140\n",
       "17     9.0          1.687534\n",
       "18     9.5          1.658932\n",
       "19    10.0          1.631283\n",
       "20    10.5          1.604540\n",
       "21    11.0          1.578661\n",
       "22    11.5          1.553603\n",
       "23    12.0          1.529328\n",
       "24    12.5          1.505799\n",
       "25    13.0          1.482984\n",
       "26    13.5          1.460850\n",
       "27    14.0          1.439367\n",
       "28    14.5          1.418507\n",
       "29    15.0          1.398242\n",
       "30    15.5          1.378549\n",
       "31    16.0          1.359402\n",
       "32    16.5          1.340780\n",
       "33    17.0          1.322662\n",
       "34    17.5          1.305026\n",
       "35    18.0          1.287855\n",
       "36    18.5          1.271129\n",
       "37    19.0          1.254833\n",
       "38    19.5          1.238949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings for exercise b\n",
    "sigma = 2\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma**2, size = n)\n",
    "\n",
    "Y = beta_ridge + epsilon\n",
    "\n",
    "# Setting the lambda from 0 to 20 with increments of 0.5\n",
    "alphas_to_try = np.arange(0.5, 20, 0.5)\n",
    "\n",
    "# Creating an empty array\n",
    "results = []\n",
    "\n",
    "# Defining a for loop to calculate the estimated values\n",
    "for alpha in alphas_to_try:\n",
    "    beta_ridge = ridge_estimator(n, alpha)\n",
    "    results.append(beta_ridge)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "alpha_results = pd.DataFrame({\n",
    "    \"Alphas\" : alphas_to_try,\n",
    "    \"Estimated values\" : results\n",
    "})\n",
    "\n",
    "alpha_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b677b7-25d8-412b-847b-2552d3ca3bab",
   "metadata": {},
   "source": [
    "#### c,  Repeat part b), say, 1000 times so that you end up with 1000 estimates of β0 for all the λ values that you have picked. For each value of λ, compute bias2 [βˆridge0], Var[βˆridge0] and MSE[βˆridge0] = bias2[βˆridge0] + Var[βˆridge0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333bf18d-93f6-471a-b766-c4d0a1429778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0119698 , -0.03593424, -0.08161019, -0.12520996, -0.16687196,\n",
       "        -0.20672257, -0.2448774 , -0.28144246, -0.31651506, -0.35018476,\n",
       "        -0.38253408, -0.41363919, -0.44357053, -0.4723933 , -0.50016796,\n",
       "        -0.52695068, -0.55279365, -0.57774548, -0.60185149, -0.62515397,\n",
       "        -0.64769243, -0.66950384, -0.69062283, -0.71108184, -0.73091135,\n",
       "        -0.75013997, -0.7687946 , -0.78690056, -0.80448171, -0.82156054,\n",
       "        -0.83815828, -0.85429497, -0.86998956, -0.88525997, -0.90012317,\n",
       "        -0.91459524, -0.9286914 , -0.94242613, -0.95581314]),\n",
       " array([0.73539133, 0.70078959, 0.66857373, 0.63852936, 0.6104656 ,\n",
       "        0.58421211, 0.55961649, 0.53654203, 0.51486582, 0.49447713,\n",
       "        0.47527598, 0.45717191, 0.44008289, 0.42393444, 0.40865879,\n",
       "        0.39419414, 0.3804841 , 0.36747706, 0.35512578, 0.3433869 ,\n",
       "        0.33222059, 0.32159023, 0.31146204, 0.30180489, 0.29259002,\n",
       "        0.28379082, 0.27538268, 0.26734274, 0.25964983, 0.25228425,\n",
       "        0.2452277 , 0.23846312, 0.23197464, 0.22574741, 0.21976761,\n",
       "        0.2140223 , 0.20849938, 0.20318751, 0.19807608]),\n",
       " array([0.73553461, 0.70208086, 0.67523396, 0.65420689, 0.63831185,\n",
       "        0.62694633, 0.61958144, 0.61575189, 0.6150476 , 0.6171065 ,\n",
       "        0.6216083 , 0.62826929, 0.6368377 , 0.64708987, 0.65882678,\n",
       "        0.67187116, 0.68606492, 0.7012669 , 0.717351  , 0.73420438,\n",
       "        0.75172607, 0.76982562, 0.78842193, 0.80744228, 0.82682143,\n",
       "        0.8465008 , 0.86642781, 0.88655523, 0.90684065, 0.92724598,\n",
       "        0.947737  , 0.96828302, 0.98885647, 1.00943263, 1.02998934,\n",
       "        1.05050675, 1.0709671 , 1.09135452, 1.11165484]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = 1000\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma**2, size = (R, n))\n",
    "\n",
    "# Creating empty arrays to store the results\n",
    "estimated_results = np.empty((R, len(alphas_to_try)))\n",
    "bias_sq = np.empty(len(alphas_to_try))\n",
    "var = np.empty(len(alphas_to_try))\n",
    "mse = np.empty(len(alphas_to_try))\n",
    "\n",
    "# Creating a for loop for the 1000 estimates\n",
    "# The 'i' stands for the number of iterations and j represents the lambas' index\n",
    "for i in range(R):\n",
    "    epsilon = np.random.normal(0, sigma, size = n)\n",
    "    Y = beta_zero + epsilon\n",
    "    for j, alpha in enumerate(alphas_to_try):\n",
    "        beta_ridge = ridge_estimator(n, alpha)\n",
    "        estimated_results[i, j] = beta_ridge\n",
    "results\n",
    "    \n",
    "# Calculating the bias squared, variance and mse results\n",
    "bias = np.mean(estimated_results - beta_zero, axis = 0)\n",
    "\n",
    "# Calculate the mean of estimated_results\n",
    "estimated_mean = np.mean(estimated_results, axis=0)\n",
    "\n",
    "# Calculate the variance using the formula\n",
    "variance = np.mean((estimated_results - estimated_mean) ** 2, axis=0)\n",
    "\n",
    "mse = np.mean(((estimated_results - beta_zero)**2), axis = 0)\n",
    "bias, variance, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31597d8-2114-48a7-b0f9-affb53c3e90b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGwCAYAAACD0J42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6U0lEQVR4nO3dd1yV5f/H8dfhsIfsKVNxooJo7pGZK3fmqq9mmmlmZvYts2Fpw3b+tBx9c7TMUWqm5p65yoELBQeCA0QEAZmHc+7fH3eiBA4UOOfA5/l4nAec+9z3fT43t3jeXPd1X5dGURQFIYQQQggTYmHsAoQQQggh/k0CihBCCCFMjgQUIYQQQpgcCShCCCGEMDkSUIQQQghhciSgCCGEEMLkSEARQgghhMmxNHYB98JgMHDp0iWcnJzQaDTGLkcIIYQQ90BRFDIzM/Hz88PConRtImYRUC5dukRAQICxyxBCCCHEfTh//jz+/v6l2sYsAoqTkxOgHmC1atWMXI0QQggh7kVGRgYBAQGFn+OlYRYB5cZlnWrVqklAEUIIIczM/XTPkE6yQgghhDA5ElCEEEIIYXIkoAghhBDC5JhFH5R7pdfr0el0xi5D3IWVlRVardbYZQghhDBhlSKgKIpCUlIS165dM3Yp4h65uLjg4+Mj49oIIYQoUaUIKDfCiZeXF/b29vKhZ8IURSE7O5vk5GQAfH19jVyREEIIU2T2AUWv1xeGE3d3d2OXI+6BnZ0dAMnJyXh5ecnlHiGEEMWYfSfZG31O7O3tjVyJKI0b50v6DAkhhCiJ2QeUG+SyjnmR8yWEEOJOKk1AEUIIIUTlIQFFCCGEECZHAooJO3fuHBqNhqioqDLf96lTp/D29sbe3p5du3aV+f6FEEKIByEBxYiGDRuGRqMpfLi7u9O1a1eOHDkCQEBAAImJiTRo0KBM3/fSpUt07tyZNm3aMGLECHr06MHRo0eLrKPT6Zg4cSINGzbEwcEBPz8/hg4dyqVLl8q0FiGEEMalN+jZddH0/lCVgGJkXbt2JTExkcTERDZv3oylpSU9evQAQKvV4uPjg6Vl2d0NnpaWVhhOli5dysyZM3n++efp0qULZ8+eLVwvOzubgwcP8vbbb3Pw4EGWL19ObGwsvXr1KrNahBBCGI+iKGyK38QTvz/B6E2j2Ze4z9glFWH246D8m6Io5Oj0RnlvOyttqe9OsbGxwcfHBwAfHx8mTpxIu3btuHLlCllZWYSEhHDo0CEiIiLQ6/U899xzbNmyhaSkJAIDAxkzZgwvvfRS4f62bdvGa6+9xvHjx7GysiIsLIxFixYRFBREdnY2jz32GG3atGHWrFlYWKj59MMPP8TBwYHOnTvz559/4uPjg7OzMxs3bixS68yZM2nWrBkJCQkEBgY+4E9LCCGEMSiKws6LO/nq0FecSD0BgJO1E1dyrhi5sqIqXUDJ0empP3m9Ud47emoX7K3v/0d6/fp1fvrpJ0JDQ3F3dycrK6vI6waDAX9/f5YuXYqHhwe7d+/mueeew9fXlwEDBlBQUECfPn0YOXIkP//8M/n5+fz111+Focne3p49e/aU+N5vvvkmb7755h3rS09PR6PR4OLict/HKIQQwnj+SvyLmYdmEnUlCgB7S3uG1B/C0LChVLOuZtzi/qXSBRRzs3r1ahwdHQHIysrC19eX1atXF7Zu3MrKyoopU6YUPg8JCWH37t0sXbqUAQMGkJGRQXp6Oj169KBmzZoA1KtXr0zqzM3N5fXXX+fJJ5+kWjXT+kcshBDizg5fOczMQzMLL+PYam0ZXHcwzzR4BldbVyNXV7JKF1DsrLRET+1itPcurQ4dOjB79mwAUlNTmTVrFt26deOvv/4qcf05c+bw7bffEh8fT05ODvn5+URERADg5ubGsGHD6NKlC506deLRRx9lwIABDzzfjU6nY9CgQRgMBmbNmvVA+xJCCFFxTlw9wVdRX7Hjwg4ALC0seaLWEzzX6Dk87T2NXN2dVbqAotFoHugyS0VzcHAgNDS08HmTJk1wdnbmf//7H88++2yRdZcuXcrLL7/M559/TsuWLXFycuLTTz9l376bHZsWLFjAuHHjWLduHUuWLOGtt95i48aNtGjR4r7q0+l0DBgwgLi4OLZs2SKtJ0IIYQbOXDvD11FfszFe7Uuo1WjpHdqbUY1G4efoZ+Tq7o35fJJXERqNBgsLC3Jycoq9tnPnTlq1asWYMWMKl505c6bYeo0bN6Zx48ZMmjSJli1bsmjRovsKKDfCyalTp9i6datMxiiEECbufOZ5ZkfNZvXZ1SgoaNDQLaQbz4c/T7BzsLHLKxUJKEaWl5dHUlISoN4C/NVXX3H9+nV69uxZbN3Q0FC+//571q9fT0hICD/88AN///03ISEhAMTFxfHNN9/Qq1cv/Pz8iImJITY2lqFDh5a6roKCAp544gkOHjzI6tWr0ev1hXW6ublhbW39AEcthBCiLCVlJTH3yFxWnlpJgVIAQMfAjoyJGENt19pGru7+SEAxsnXr1hX2EXFycqJu3bosW7aMhx9+mHPnzhVZd/To0URFRTFw4EA0Gg2DBw9mzJgx/PHHH4B6l87Jkyf57rvvuHr1Kr6+vowdO5ZRo0aVuq4LFy6watUqgMI+Ljds3bqVhx9+uNT7FEIIUbau5lzl26PfsjRmKfmGfABa+7XmxcYvEuYRZuTqHoxGURTF2EXcTUZGBs7OzqSnpxfrA5Gbm0tcXBwhISHY2toaqUJRWnLehBDi/qXnpfPd8e/48cSP5BSoXQIivSIZFzmOJt5NjFzdTXf6/L4baUERQgghzES2LpufTvzEguMLyMzPBCDMPYwXG79IK79WpR4s1JRJQBFCCCFMXJ4+jyUnlzDv2DxSc1MBCHUJZWzjsTwS8EilCiY3SEARQgghTJTOoGPl6ZXMOTyH5OxkAAKdAhkTMYauwV3RWpR+/C1zIQFFCCGEMDF6g54/zv3BrKhZnM88D4CPgw+jG42mV2gvrCysjFxh+ZOAIoQQQpgIRVHYkrCFr6K+4vS10wC42brxXKPneKL2E9hobYxcYcWRgCKEEEIYmaIo7Lm0h5mHZnLs6jFAnWF4eIPhPFn3Seyt7I1cYcWTgCKEEEIY0aHkQ8w4OIP9l/cDYGdpx3/q/YdhDYaZ3AzDFUkCihBCCGEEJ66eYOahmey8uBMAKwsrBtYZyLMNn8XdTqYWkYBSyWg0GlasWEGfPn2MXYoQQogSnE0/y9eHvmZD/AZAncivT2gfRoePxsfBx8jVmQ4JKEbQs2dPcnJy2LRpU7HX9uzZQ6tWrThw4ACRkZGl3ndiYiKurq5lUaYQQogydOn6JWYfns2qM6swKIbCifzGRIwhqFqQscszORJQjGDEiBE8/vjjxMfHExRU9B/l/PnziYiIKHU4yc/Px9raGh8fSd9CCGFKUnJS+ObINyyLXUaBQZ3I7+GAhxkbMZY6bnWMXJ3psjB2AVVRjx498PLyYuHChUWWZ2dns2TJEvr06cPgwYPx9/fH3t6ehg0b8vPPPxdZ9+GHH2bs2LFMmDABDw8POnXqBKiXeFauXFm43sSJE6lduzb29vbUqFGDt99+G51OV/j6u+++S0REBD/88APBwcE4OzszaNAgMjMzC9cxGAx8/PHHhIaGYmNjQ2BgIB988EHh6xcvXmTgwIG4urri7u5O7969i010KIQQVU16XjrTD0yn26/d+PnkzxQYCmju25yfHvuJmY/MlHByF5WvBUVRQJdtnPe2sod7GG7Y0tKSoUOHsnDhQiZPnlw4RPGyZcvIz8/n2Wef5eeff2bixIlUq1aNNWvWMGTIEGrUqEHz5s0L9/Pdd9/x/PPPs2vXLm4356OTkxMLFy7Ez8+Po0ePMnLkSJycnHjttdcK1zlz5gwrV65k9erVpKWlMWDAAD766KPCEDJp0iT+97//8eWXX9KmTRsSExM5efIkoIaqDh060LZtW3bs2IGlpSXvv/8+Xbt25ciRI1hbW9/3j1MIIcxRti6bH0/8yMJjC8nUqX/sNfJsxLjG42ju2/wuW4sbKt9sxvlZ8KGfcQp94xJYO9zTqidPnqRevXps2bKFDh06ANC+fXuqV6/OokWLiq3fvXt36tWrx2effQaoLSjp6ekcOnSoyHp36yT76aefsmTJEvbvV29ne/fdd/n0009JSkrCyckJgNdee40dO3awd+9eMjMz8fT05KuvvuLZZ58ttr/58+fzySefcOLEicKglZ+fj4uLCytXrqRz584l1iGzGQshKps8fR5LY5by7dFvC+fLqeVai3GNx9Hev32lnC/nbmQ2YzNUt25dWrVqxfz58+nQoQNnzpxh586dbNiwAb1ez0cffcSSJUu4ePEieXl55OXl4eBQNPw0bdr0ru/zyy+/MH36dE6fPs3169cpKCgo9o8kODi4MJwA+Pr6kpyszvlw4sQJ8vLy6NixY4n7P3DgAKdPny6yPagB5MyZM/f0sxBCCHNWYCjgt9O/MfvwbC5nXwbU+XLGNh5Ll+AuWGikN8X9qHwBxcpebckw1nuXwogRIxg7dixff/01CxYsICgoiI4dO/Lpp5/y5ZdfMn36dBo2bIiDgwPjx48nPz+/yPb/Diz/tnfvXgYNGsSUKVPo0qULzs7OLF68mM8//7xo2VZF53TQaDQYDAYA7Ozs7vgeBoOBJk2a8NNPPxV7zdPT847bCiGEOTMoBtafW8/XUV8TnxEPgLe9N8+HP19l5sspT5UvoGg093yZxdgGDBjASy+9xKJFi/juu+8YOXIkGo2GnTt30rt3b/7zn/8Aagg4deoU9erVK9X+d+3aRVBQEG+++Wbhsvj4+FLto1atWtjZ2bF58+YSL/FERkayZMkSvLy8St18J4QQ5khRFHZc2MGMQzOITYsF1Plynm34LAPqDKhS8+WUJ2l3MiJHR0cGDhzIG2+8waVLlxg2bBgAoaGhbNy4kd27d3PixAlGjRpFUlJSqfcfGhpKQkICixcv5syZM8yYMYMVK1aUah+2trZMnDiR1157je+//54zZ86wd+9e5s2bB8BTTz2Fh4cHvXv3ZufOncTFxbF9+3ZeeuklLly4UOqahRDClP2d9DdD/hjC2C1jiU2LxdHKkRcbv8gfj//BkPpDJJyUocrXgmJmRowYwbx58+jcuTOBgYEAvP3228TFxdGlSxfs7e157rnn6NOnD+np6aXad+/evXn55ZcZO3YseXl5dO/enbfffpt33323VPt5++23sbS0ZPLkyVy6dAlfX19Gjx4NgL29PTt27GDixIk8/vjjZGZmUr16dTp27CgtKkKISuNYyjFmHJzBnsQ9ANhqbXmy3pMMbzAcZxtnI1dXOVW+u3iEWZDzJoQwB6fTTvNV1FdsTtgMgKWFJU/UeoLnGj2Hp730s7sbuYtHCCGEKEPnM88zO2o2q8+uRkHBQmNBjxo9eD78efyd/I1dXpVQ6j4oO3bsoGfPnvj5+RUbtfR2tm/fTpMmTbC1taVGjRrMmTPnfmoVQgghylVydjLv732fXit68fvZ31FQ6BTUieW9lvNBmw8knFSgUregZGVlER4ezjPPPEO/fv3uun5cXByPPfYYI0eO5Mcff2TXrl2MGTMGT0/Pe9peCCGEKG/Xcq8x/9h8Fp1cRJ4+D4BWfq0Y13gcYR5hRq6uaip1QOnWrRvdunW75/XnzJlDYGAg06dPB6BevXrs37+fzz77TAKKEEIIo8rSZfFD9A98d/w7ruuuAxDhGcG4yHE85POQkaur2sq9D8qePXuKDXfepUsX5s2bh06nKzZIGFA4cuoNGRkZ5V2mEEKIKiRPn8eSk0v49ui3pOWlAVDHtQ7jIsfRtnrbKjksvakp94CSlJSEt7d3kWXe3t4UFBSQkpKCr69vsW2mTZvGlClTyrs0IYQQVUxJw9IHVQtibMRYOgd3lmHpTUiF3MXz7yR6487m2yXUSZMmMWHChMLnGRkZBAQElF+BQgghKrXbDUs/JmIMvWr2wtJCbmo1NeV+Rnx8fIqNgpqcnIylpSXu7u4lbmNjY4ONjYzGJ4QQ4sEoisLOizuZcXAGMWkxALjauDKy0UgZlt7ElXtAadmyJb///nuRZRs2bKBp06Yl9j8RQgghysLfSX8z4+AMoq5EAeBo5ciwsGH8p/5/cLAyjznbqrJSB5Tr169z+vTpwudxcXFERUXh5uZGYGAgkyZN4uLFi3z//fcAjB49mq+++ooJEyYwcuRI9uzZw7x58/j555/L7iiEEEKIfxy/epwZB2ew+9JuQB2WfnC9wYxoMEKGpTcjpe4NtH//fho3bkzjxo0BmDBhAo0bN2by5MkAJCYmkpCQULh+SEgIa9euZdu2bURERPDee+8xY8YMucUYGDZsGBqNpnBem1uNGTMGjUZTOIFgcnIyo0aNIjAwEBsbG3x8fOjSpQt79uwp3CY4OBiNRlPs8dFHH1XUIQkhhNGcuXaGCdsmMGj1IHZf2o2lxpKBdQay5vE1TGgyQcKJmSl1C8rDDz/MnabvWbhwYbFl7du35+DBg6V9qyohICCAxYsX8+WXX2JnZweo89T8/PPPhZMHAvTr1w+dTsd3331HjRo1uHz5Mps3byY1NbXI/qZOncrIkSOLLHNycir/AxFCCCO5eP0is6JmsfrsagyKAQ0aetbsyejw0QQ4yQ0W5kq6LRtZZGQkZ8+eZfny5Tz11FMALF++nICAAGrUqAHAtWvX+PPPP9m2bRvt27cHICgoiGbNmhXbn5OTEz4+PhV3AEIIYSRXsq/wzZFv+OXULxQYCgB4NPBRXoh4gVDXUCNXJx5UpQsoiqKQU5BjlPe2s7S7r8F9nnnmGRYsWFAYUObPn8/w4cPZtm0bAI6Ojjg6OrJy5UpatGghdzgJIaq09Lx0FhxbwE8nfiJXnwtAS9+WjIscRwOPBkauTpSVShdQcgpyaL6ouVHee9+T+7C3si/1dkOGDGHSpEmcO3cOjUbDrl27WLx4cWFAsbS0ZOHChYwcOZI5c+YQGRlJ+/btGTRoEI0aNSqyr4kTJ/LWW28VWbZ69Woefvjh+z0sIYQwCdm6bH488SMLjy0kU5cJQLhnOOMaj6OZb/EWZWHeKl1AMUceHh50796d7777DkVR6N69Ox4eHkXW6devH927d2fnzp3s2bOHdevW8cknn/Dtt98WdqQFePXVV4s8B6hevXoFHIUQQpSPPH0ey2KW8b+j/yM1V+13V9u1Ni82fpH2/u1lWPpKqtIFFDtLO/Y9uc9o732/hg8fztixYwH4+uuvS1zH1taWTp060alTJyZPnsyzzz7LO++8UySQeHh4EBoq116FEOavwFDAqjOrmH14NklZ6oCfgU6BjG08li7BXWRY+kqu0gUUjUZzX5dZjK1r167k5+cD6mSK96J+/fqsXLmyHKsSQoiKZ1AMbDi3ga+ivioyLP3z4c/TK7QXVhYyyGdVUOkCirnSarWcOHGi8PtbXb16lf79+zN8+HAaNWqEk5MT+/fv55NPPqF3795F1s3MzCw2tYC9vT3VqlUr3wMQQogHJMPSi1tJQDEhtwsRjo6ONG/enC+//JIzZ86g0+kICAhg5MiRvPHGG0XWnTx5cuGgeTeMGjWKOXPmlFvdQgjxoGRYevFvGuVOo66ZiIyMDJydnUlPTy/2IZ6bm0tcXBwhISHY2toaqUJRWnLehBAAx1KOMePgDPYkqqNi22ptebLekwxvMFxGfq0E7vT5fTfSgiKEEKLCnUo7xVeHvmLL+S0AWFpY0q9WP0Y1GoWnvaeRqxOmQAKKEEKICnM+4zxfH/6atWfXoqBgobGgZ42ePB/xPNUdZUgEcZMEFCGEEOUuKSuJb458w4pTKyhQ1GHpOwd15oWIF6jhUsPI1QlTJAFFCCFEuUnNTWXe0XksPrmYfIM6lEKb6m14sfGL1Hevb+TqhCmrNAHFDPr6ilvI+RKicsvMz+S749/xQ/QPZBdkAxDpFclLkS8R6R1p5OqEOTD7gGJlpQ7Yk52djZ3d/Y/kKipWdrb6H9aN8yeEqByyddksOrmIBccWkJGfAUB99/qMazyOVn6tZFh6cc/MPqBotVpcXFxITk4G1EHJ5BfAdCmKQnZ2NsnJybi4uBQblE4IYZ7y9fksi13G/478j6u5VwGo4VyDFxu/SMfAjvL/sig1sw8oAD4+PgCFIUWYPhcXl8LzJoQwXwWGAn47/RtzjswpnC/H39GfMRFjeCzkMbQW8keIuD+VIqBoNBp8fX3x8vJCp9MZuxxxF1ZWVtJyIoSZMygG1sWt4+uor0nITADAy96LUY1G0bdWX5kvx4xczytg5aGLPNU80KRauipFQLlBq9XKB58QQpQjRVHYen4rX0V9xam0U4A6X86zDZ9lQJ0B2FrKyNDmZFtMMm+uOMbFazk42VrSO8J0xqKpVAFFCCFE+VAUhT2Je/jq0FccTTkKgJOVE0+HPS3z5ZihtKx83lsdzfJDFwEIcLPD08m0JmOUgCKEEOKODl4+yMxDM9l/eT8AdpZ2PFXvKYaFDZP5csyMoiisOZrIO78d52pWPhoNDG8dwiuda2NvbVqRwLSqEUIIYTKOpxxnZtRMdl3cBYCVhRUD6gzg2YbP4mHnYeTqRGldzsjlrZXH2Bh9GYDa3o581K8RkYGuRq6sZBJQhBBCFBGbFsvXh76+OZGfxpI+tfowqtEofBzk7jtzoygKi/8+z4drT5CZW4CVVsMLHUIZ83Ao1pYWxi7vtiSgCCGEAOBc+jlmHZ7Furh1KCho0NCjRg+eD3+egGoBxi5P3IdzKVlMWn6UPWfVsWnCA1z4pF8j6vg4Gbmyu5OAIoQQVdzF6xeZe3guq86sQq/oAXUivzERY6jpUtPI1Yn7UaA3MH9XHF9sjCVXZ8DWyoL/dq7DM61D0FqYzq3EdyIBRQghqqjk7GS+OfINv576lQKDOsNwe//2jG08lrpudY1cnbhfJ5MyeO2XIxy5kA5Aq5rufPR4IwLd7Y1cWelIQBFCiCrmas5V5h+bz5KYJeTp8wBo4duCsY3HEu4ZbuTqxP3KLzDw9dbTzNp2Gp1ewcnWkre716d/U3+TGoDtXklAEUKIKiI9L50Fxxaw6OQicgpyAIjwjGBc5Dge8nnIyNWJB3H4/DUm/nqEk0mZAHSu7817fRrgXc18B86TgCKEEJVcZn4mP0T/wPfR35OlywIgzD2MsY3H0tqvtVn+dS1UuTo9X26M5X87z2JQwN3Bmim9w+je0Nfsz6sEFCGEqKSyddn8dOInFh5fSEZ+BgB1XOvwQsQLPBzwsNl/gFV1f59L5bVfjhCXoobO3hF+vNMzDDcHayNXVjYkoAghRCWTU5DD0pilzDs6j7S8NABqONfghYgXeDToUSw0pjv2hbi7rLwCPll3ku/3xqMo4OVkwwd9G9KpvrexSytTElCEEKKSyNfnsyx2Gd8e/ZaUnBQAAp0CeT7ieboFd0NrIZOpmrs/T6Xw+vIjXEhT+xANbBrAG93r4WxX+WaPloAihBBmTqfXseL0Cv539H8kZSUB4Ofgx+jw0fSs2RNLC/mv3tyl5+j4cM0Jluw/D0B1Fzs+6teQtrU8jVxZ+ZF/tUIIYaZ0Bh2/n/mduYfncinrEgBe9l6MajSKvqF9sdJWvr+qq6LNJy7zxoqjXM5Qbwl/umUQr3Wti4NN5f4Ir9xHJ4QQlVCBoYA1Z9cw5/AcLly/AICHnQfPNnyWJ2o/gY3WxsgVirJwLTufqb9Hs/zQRQBCPBz4uF8jmoW4GbmyiiEBRQghzITeoGdt3FrmHplLfEY8AG62boxoMIIBdQZga2m+Y16IotYfT+Ktlce4kpmHhQaebVuDCZ1qY2tVdfoRSUARQggTZ1AMrD+3ntmHZxOXHgeAi40LwxsMZ2CdgdhbmdcQ5uL2UrPyeXfVcVYdVi/Z1fR04NP+4UQGuhq5soonAUUIIUyUQTGwKX4Tsw/P5vS10wBUs67GMw2eYXDdwThYORi5QlGW/jiayNu/HSPlej4WGhjVviYvdaxVpVpNbiUBRQghTIxBMbAlYQuzD88mNi0WACcrJ4aGDeU/9f6Do7WjkSsUZSnleh7v/HacNUcTAajt7cinT4QTHuBi3MKMTAKKEEKYCINiYGvCVmYfnk1MWgwADlYODKk/hCH1h1DNupqRKxRlSVEUVh9J5J1Vx0nNykdroeH59jV5sWMoNpZVs9XkVhJQhBDCyBRFYcv5Lcw5PIeTqScBNZg8Ve8phtYfirONs5ErFGXtSmYeb688xrrj6rg1dX2c+PSJcBr6y7m+QQKKEEIYSUnBxN7SvjCYuNi6GLdAUeYURWHV4Uu8s+o417J1WFpoeKFDKC90CMXaUqYguJUEFCGEqGCKorD1/FbmHJ7DidQTgASTquBKZh5vrTzK+uOXAajvW41P+zcizE9aTUoiAUUIISqIoihsO7+N2YdnSzCpQm70NZn82zHS/mk1efGRWozpUBMrrbSa3I4EFCGEKGfSYlJ1pVxX+5r8cUzta1Lftxqf9Q+nvp90eL4bCShCCFFODIqBzQmbmXt4buFdOXaWdoXBxNW26g2+VZWsOaKOa5KalS99Te6DBBQhhChjeoOejQkbmXt4buEAaw5WDjxZ90mG1B8iwaSSu3o9j8m3jGtS18eJz/qH06C69DUpDQkoQghRRvQGPevPrWfukbmcTT8LgKOVI0/Ve4oh9YfI7cJVwB9HE3lr5TGu/jOuyQsP12TsI7Wk1eQ+SEARQogHVGAo4I+4P/jmyDecyzgHgJO1E0PqD+Gpek/JAGtVQGpWPpN/O8bqI9JqUlYkoAghxH3SGXSsObuG/x35HwmZCQA42zgztP5QBtcdjJO1k5ErFBVh/fEk3lxxlJTraqvJmIdr8qK0mjyw+/rpzZo1i5CQEGxtbWnSpAk7d+684/o//fQT4eHh2Nvb4+vryzPPPMPVq1fvq2AhhDC2fH0+S2OW0nNFT97e9TYJmQm42LjwUuRLrO+3nucaPSfhpApIz9bx8pIoRv1wgJTr+dT2dmTlmNa80rmOhJMyUOoWlCVLljB+/HhmzZpF69atmTt3Lt26dSM6OprAwMBi6//5558MHTqUL7/8kp49e3Lx4kVGjx7Ns88+y4oVK8rkIIQQoiLkFOTwa+yvLDi+gOTsZADcbN0YFjaMgXUGYm9lb+QKRUXZGpPM678e4XJGHhYaGN2+Ji89Wkvm0ClDGkVRlNJs0Lx5cyIjI5k9e3bhsnr16tGnTx+mTZtWbP3PPvuM2bNnc+bMmcJlM2fO5JNPPuH8+fMlvkdeXh55eXmFzzMyMggICCA9PZ1q1eRarhCiYmXpslgSs4Tvjn9Ham4qAF52XjzT4Bn61e6HnaWdkSsUFSUzV8f7q0+wZL/6+VXD04HP+4fTOFDuzCpJRkYGzs7O9/X5XaoWlPz8fA4cOMDrr79eZHnnzp3ZvXt3idu0atWKN998k7Vr19KtWzeSk5P55Zdf6N69+23fZ9q0aUyZMqU0pQkhRJlLz0tn0clF/Bj9Ixn5GQBUd6zO8AbD6RPaB2uttZErFBVp1+kUXvvlCBev5aDRwPDWIbzapQ62VtJqUh5KFVBSUlLQ6/V4e3sXWe7t7U1SUlKJ27Rq1YqffvqJgQMHkpubS0FBAb169WLmzJm3fZ9JkyYxYcKEwuc3WlCEEKIipOam8kP0D/x88meydFkABFcLZmSjkXQL6YaVhZWRKxQVKSuvgI/+OMkPe+MBCHSz57P+4TQLcTNyZZXbfd3Fo9FoijxXFKXYshuio6MZN24ckydPpkuXLiQmJvLqq68yevRo5s2bV+I2NjY22NjY3E9pQghx3y5nXea76O9YFrOMXH0uALVca/Fco+foFNgJrYX8pVzV/BWXyn+XHSYhNRuAIS2CeL1bXRxs5CbY8laqn7CHhwdarbZYa0lycnKxVpUbpk2bRuvWrXn11VcBaNSoEQ4ODrRt25b3338fX1/f+yxdCCHKRnxGPAuOLWDVmVXoDDoAwtzDGNVoFO0D2mOhkTsyqppcnZ5P18cwf1ccigJ+zrZ88kQ4bWp5GLu0KqNUAcXa2pomTZqwceNG+vbtW7h848aN9O7du8RtsrOzsbQs+jZarfpXSCn75wohRJk6mXqSeUfnsSF+AwbFAECkVySjGo2ipV/L27YMi8ot6vw1JiyN4uwV9fLegKb+vNWjPtVs5dJeRSp1G9WECRMYMmQITZs2pWXLlnzzzTckJCQwevRoQO0/cvHiRb7//nsAevbsyciRI5k9e3bhJZ7x48fTrFkz/Pz8yvZohBDiHhy4fIBvj37Lnxf/LFzWzr8dzzZ8lsZejY1YmTCm/AIDM7ecYta2M+gNCl5ONnzUryGP1C35CoEoX6UOKAMHDuTq1atMnTqVxMREGjRowNq1awkKCgIgMTGRhISEwvWHDRtGZmYmX331Fa+88gouLi488sgjfPzxx2V3FEIIcReKorDz4k7mHZ3HweSDAFhoLOgS1IURDUdQx62OkSsUxnQyKYMJSw4TnajerdUr3I+pvcNwsZc7tYyl1OOgGMOD3EcthKja9AY9G+I3MO/oPGLSYgCwsrCid2hvngl7hsBqxQeYFFWH3qDwzY6zfLkxlny9AVd7K97v05DujaR/ZFmosHFQhBDCXOTp81h1ZhULjy0snCfHztKOAbUHMDRsKF72XkauUBjbuZQsXll2mAPxaQA8Ws+LDx9viJeTrZErEyABRQhRyaTnpbM0Zik/nvixcNRXZxtnnqr7FIPrDsbF1sW4BQqjMxgUftwXz7S1J8nR6XG0sWRyz/r0b+IvHaNNiAQUIUSlkHg9kR9O/MAvsb+QU5ADgI+DD0PrD6VfrX4yT44A4NK1HF775Qh/nk4BoGUNdz7t3wh/V/n3YWokoAghzFpsWiwLjy3kj7g/KFAKAHVwtWfCnqFrSFcZ9VUAaifp5Qcv8u7vx8nMLcDWyoLXu9ZlaMtgLCyk1cQUSUARQpgdRVHYf3k/84/NL3KrcDOfZjzT4Bla+7WWpnpRKOV6Hm8sP8qG6MsARAS48MWAcGp4Ohq5MnEnElCEEGZDb9CzOWEzC44t4NjVY4B6q/CjgY/yTINnaODRwMgVClOz4XgSb6w4Ssr1fKy0GsY/WptR7WpgqZXRgU2dBBQhhMnL0mWx8vRKfoj+gYvXLwJgo7WhT2gfhtYfKrcKi2Iyc3VM/T2aZQcuAFDH24kvBoYT5uds5MrEvZKAIoQwWUlZSSw6sYhfYn8hU5cJqHfkDKwzkCfrPom7nbuRKxSmaO/Zq7yy9DAXr+Wg0cBzbWswoXNtbCxlskdzIgFFCGFyjl89zvfHv2fDuQ2FHV+DqwUzpP4QetbsiZ2lnZErFKYoV6fn8w0xfPunOsFfgJsdn/ePoFmIm7FLE/dBAooQwiQYFAPbzm/j++jvOXD5QOHyh3weYmj9obTzbyezCovbOnYxnZeXRHEq+ToAgx4K4K0e9XG0kY85c1Wlz1zi5SPM2/Emr/ZahI2Nk7HLEaJKytZls+rMKn6I/qFwxFdLjSVdQ7oypP4Q6rvXN3KFwpQV6A3M2X6G6ZtOUWBQ8HC04eN+DelYTyb4M3dVNqAY9AW8tHYoJyz0nFzcgf/r/QvuLsHGLkuIKuPS9UssjlnMr7G/kpGvTtDmZO1E/9r9GVx3MD4OPkauUJi6uJQsJiyN4lDCNQC6hvnwQd8GuDvaGLcwUSaqbECx0Fry34bPMf7o1xy2yOOpFb34utNcavq3NHZpQlRaN8Yv+enET2w9vxWDYgDA39Gf/9T/D31D+8qIr+KuFEXhx30JfLjmBDk6PU62lkztHUafiOoy/k0lUuVnM447tZYXdrzKeUsLHA0Knzd7i1Zhg8r0PYSo6nIKclh7di0/nfyJU2mnCpe38G3Bk3WfpJ1/O7QWcoeFuLvkjFxe+/UI22KuANCqpjuf9Q/Hz0U6TpuiB/n8rvIBBSAt6TDj1wzhoKWCVlF4s/aT9G/1Rpm/jxBVTeL1RPUyzqlfSc9LB9QZhXvW6MnguoMJdQ01coXCnPxxNJE3VhwlLVuHjaUFE7vWZVgrGarelElAKQP5mUm880svVluok4w97dWCl7vMkb/qhCglRVE4cPkAi04uYnPC5sLLONUdqzO47mD6hPbB2UYGyxL3LiNXx7urjrP8oDpIX5hfNaYPjKCWt9zcYOokoJQRJT+bOct6M6sgCYBHHAKZ1msp9tYO5faeQlQWWbos1pxdw5KYJcSmxRYub+7TnCfrPUl7//YS+EWp3TromoUGxjwcyriOtbC2lFvOzYEElLJkMLD2t2G8lX4QnUZDPa0TX/X5FS9H3/J9XyHMVGxaLEtjlvL7md/JLsgGwFZrS8+a6mWcWq61jFyhMEd5BXq+2BDLNzvPoigQ6GbPFwPCaRosg66ZEwko5eDQlrd46dxy0rRavLDk664LqOsdUSHvLYSpy9PnsTF+I0tjlnIo+VDh8uBqwQyoM4BeNXvJZRxx304kZvDykihOJqnTG8iga+ZLAko5OX9wHi8c/Iw4K0vsFA2ftfmAdqE9K+z9hTA15zPOsyx2GStPryQtLw1QB1XrENiBgXUG0synmdzmKe6b3qAw78+zfLY+lny9AXcHaz7q14hO9WXQNXMlAaU83/v0ZiZsGcs+G0ssFHg1bARPNX1J/hMWVUaBoYAdF3awNGYpuy7tKlzu4+DDE7We4PFaj+Np72nECkVlcCEtm1eWHmZfXCoAj9bzYtrjjfB0kkHXzJkElHKmuxzN+ysHstxWff6IRwSTH5kuM6mKSu185nlWnFrBb2d+Izk7GQANGlpVb8XA2gNp698WSwtpchcPRlEUVkZdZPLK42TmFWBvrWVyj/oMfChA/hCsBCSgVAAlI4nvl/ZiumU2BRoNblp7Jrf9kI5BHY1SjxDlIbcgl00Jm1hxagV/Jf1VuNzVxpU+tfrQv3Z/ApwCjFihqEzSs3W8ufIoq48kAhAZ6MKXAyMIcpc7JysLCSgVJT+LmF+fZtL1o5yytgagZ0h3Xm/xBtWsjViXEA8o+mo0y08tZ23cWjLz1Y6JGjS08mtF31p96RDQAWuttZGrFJXJrtMpvLL0MEkZuWgtNIzvWIvnH66JpVZuH65MJKBUJIOB/O0fMevIHBY4V8Og0eBt58nUNu/Tyq+VcWsTohTS89JZG7eW5aeWczL1ZOFyPwc/+oT2oU9oH3zl9npRxnJ1ej5bH8O3f8YBEOLhwJcDI4gIcDFuYaJcSEAxhuhVRK15gTddHUiwsgJgUJ1BvNzkZZnsTJgsvUHPX0l/sfL0SjbFbyLfkA+AlYUVHQM70rdWX1r4tsBCI3/FirJ3MimD8Ytv3j78VPNA3uxeD3tr6ctUWUlAMZako2T//CRfWmayuJo65HKgUyAftPmACK8I49YmxC1iUmNYfXY1a8+uJTknuXB5Ldda9KvVj+4h3XGxdTFegaJSMxgU5u+K45N1MYW3D3/yRCM61pPbhys7CSjGlJUCS4ey+/IB3vZ0I9nSEguNBc+EPcOYiDFy3V4YTVJWEmvj1rL67OoiMwhXs65G1+Cu9K3VlzD3MLlTQpSrS9dy+O+yw+w+cxWAjnW9+Kif3D5cVUhAMbaCfPjjVTIOfcdHbm787qT2QK/tWpsP23xIHbc6Ri5QVBVZuiw2xm9k9dnV/JX4Fwrqr7eVhRXt/dvTo2YP2lZvK8FZVIhVhy/x1oqjZOQWYGel5e0e9RncTG4frkokoJgCRYG/v4U/JrLZzpqpXl6kahS0Gi19QvvwfPjzeDtIc6YoezqDjj2X9rD6zGq2nt9Krj638LVIr0h61OxB56DOMvS8qDAZuTre+e04Kw6psw+HB7jw5YBwang6GrkyUdEkoJiSs9th2dNczUvnAx8/NtqonQ1ttbY8Ve8phjccLrckiwemM+j4K/Ev1p9bz5bzW0jPSy98LbhaMD1r9uSxkMfwd/I3YpWiKvorLpWXl0QVzj48tkMoL3ashZXcPlwlSUAxNaln4efBcOUkB+0dmR7SgEPZlwD1+v+zDZ9lcN3B2FraGrlQYU50Bh37Evex4dyGYqHEzdaNbiHd6FmjJ/Xd60sTuqhwOr2B/9t0ilnbTmNQIMDNjukDI2gSJLMPV2USUExRbgasGA0xa1CA7fU783/W+ZxOPwuAt703L0S8QM+aPWW4cHFbOr2OvYl72RC/gS0JW8jIzyh8zc3WjU5Bnegc1Jkm3k3QWmiNWKmoyuJSshi/+BCHL6ih+fHI6kzpFYaTrZWRKxPGJgHFVBkMsHsGbJ4CigG9Z11Wtx7B16d/ITFLHdq5hnMNxkWO45GAR+SvXgFAvj5fbSkpIZS427rzaNCjdAnuQqRXpIQSYVSKorD47/NM/T2aHJ2earaWfPh4Q3o08jN2acJESEAxdef+hF+Gw/XLYO1IXo/PWaLN55uj3xQ204d7hjM+cjxNfZoauVhhDCk5Key8sJPtF7az+9JucgpyCl+TUCJMUWpWPq//eoQN0ZcBaFnDnc8HhOPnYmfkyoQpkYBiDjIvw68j4NxO9XmzUWQ+PJEFJ3/ixxM/Fn4gtfRtyaC6g2jn304u/VRiiqIQmxbLtvPb2HFhB0dTjhbeEgzgaedJx8COdA7uLKFEmJwdsVd4ZdlhrmTmYaXV8N/OdRjZtgYWFtIKLIqSgGIu9AWw9QP48wv1efWm0H8hV6xtmXtkLr/G/kqBUgCAl70X/Wr14/Faj+Pj4GPEokVZydPnsS9xHzsu7GD7he0kZSUVeb2+e30e9n+YdgHtqO8mHV2F6cnV6fl43UkW7DoHQKiXI9MHRtCgutzCLkomAcXcxKyDFc9BbjrYucLj30KtRzmfeZ5lsctYeWolaXlpAFhoLGjn344BtQfQyq+V/CVtRhRF4Wz6WfYm7mVv4l72Je4rcunGVmtLC78WtPdvTzv/dnjZexmxWiHu7GRSBi/9HEXMZXUenaEtg5jUrR521vJ/krg9CSjmKO0cLH0aEqMADbT7Lzw8CSy05Ovz2ZywmaUxS9l/eX/hJtUdq9OvVj/61uqLh52HsSoXd5B4PVENI0n7+CvxL67kXCnyure9N+3929M+oD3NfJrJrebC5CmKwoJd5/ho3UnyCwx4OKrz6DxSVwaeFHcnAcVcFeTB+jfUEWgBQtpDv3ng6Fm4ytlrZ1kWu4zfzvxGZr76l4ulxpIOgR0YUGcAzXyaycyzRpSam8pfSX+xL3Ef+xL3cT7zfJHXbbQ2RHhF0MK3BW2qt6GOax25dCPMRnJmLq8uO8L2WDVoP1LXi49lHh1RChJQzN2RZfD7ONBlg6MP9J0DNTsUWSW3IJf159azNHYpR64cKVzuZe9F2+ptaevflha+LXCwcqjo6qsMRVG4nH2Zw1cOc/jKYf5K/IuYtJgi62g1WsI8wmju05wWvi0I9wrHRiv/mQvzs/nEZV775QhXs/KxsbTgze71GNIiSAK2KBUJKJVB8klYOhRS/vnAazkWOk4Gy+IfbjGpMSyLXcbqs6vJ0mUVLre0sKSJdxPaVm9LO/92BFcLlv9MHkC2Lpvoq9EcSTnCkSvq49+XbABqudaiuU9zmvs2p6l3UxytZb4RYb5ydXo+XHuC7/fEA1DXx4kZgxtT29vJyJUJcyQBpbLIz4YNb8L++epzn0bqJR/P2iWunluQy/7L+9l5YSc7LuzgwvULRV73d/SnrX9b2lZvy0M+D0l/hztQFIX4jPgiYSQ2LRa9oi+ynlajpbZrbRp5NqKJdxMe8nlI+gOJSiP6UgYvLT7EqeTrAIxoE8KrXepgayUdYcX9kYBS2ZxcA7+NhZxUsLSDrh9Ck2fgDq0hNz5gd17cyc4LO9l/eT86g67wdRutDc18mhHpHUkd1zrUdauLp73nbfdXWSmKwtXcq5xKO8WZa2c4fe00p6+d5sy1M1zXXS+2vpedF+Fe4TTyaEQjz0bUc6+HnaUMRCUqF4NBYf6uOD5ZF0O+3oCnkw2f9Q+nfe2q93+EKFsSUCqjjERYORrOblOf1+0BvWaC/b1NvJWty2Zf4j52XlRbVy5nXy62jrutO3Xd6lLHrU7h1yCnoEpzK3Nablph+LgRRE5fO11kkr1b2WhtCHMPo5FnIxp6NKSRZyMZg0ZUeskZubyy7DA7T6UA8Gg9bz7u1xB3R+k7JR6cBJTKymCAvV/Dpilg0IGTr9qBtsbDpdqNoiicunaK3Rd3E50aTUxqDOcyzmFQDMXWtdXaUtu1NnXc6lDHtQ6+jr542nniae+Jq42ryYQXnUFHcnYyidcTScpOIimr6CMxK7HIHDa3stBYEOgUSE2XmtR0qUktl1rUdKlJsHMwVhYyuZmoOjZGX+a1Xw6Tlq3D1sqCt7rX56nmgdJ3TZQZCSiVXeJh+PVZSIkFNNDqRXjkbbC0vu9d5hTkcDrtNCfTThKTGsPJ1JPEpsUWGUjs37QaLW62bnjYeeBp74mnnaf6vZ0nHvYeuNu6Y621RqvRYmVhhdZCi6WFJZYaS7QW/yzT/LPsn2H8s3RZZOuyua67Xuz7wkdBFln5WaTlpXE56zJJWUlcyblSZGj426nuWJ1Ql1BCXULVMOJai+BqwdIfR1RpOfl63l8TzU/7EgCo71uNGYMjCPWSjrCibElAqQrys9UxUw4sUJ/7hqsdaD1qldlb6A16zmeeLwwtp9JOkZydTHJ2Mqm5qfcUCCqStYU1Pg4+xR/2Pvg6+OLn6Ie9lb2xyxTCpERfymDc4kOc/qcj7Mi2Ify3Sx1sLE2jdVRULhJQqpITq2HVWMhJAyt76PLBXTvQloUCQwGpualcyblCSnYKV3KuFPk+JSeF1NxUdAYdBYYC9Ipe/WpQv96YY6gkVhZWOFo5Ym9lj6OVIw5WDsUejlaOVLOpho+9Dz6Oaghxs3WTpmgh7lHhiLB/nCzsCPvFgHDa1pKOsKL8VHhAmTVrFp9++imJiYmEhYUxffp02rZte9v18/LymDp1Kj/++CNJSUn4+/vz5ptvMnz48Ht6Pwko/5KRCCtGQdx29XmNDmoHWpcA49Z1B4qi3Awt/3xVFAV7K3ustfd/qUoIcXdXMvP477LDhSPCPlpPHRFWOsKK8vYgn9+WpX2zJUuWMH78eGbNmkXr1q2ZO3cu3bp1Izo6msDAwBK3GTBgAJcvX2bevHmEhoaSnJxMQcHt/6IWd1HNF4ashH2zYfNUOLsVZrWELu9D5NPl3ppyPzQaDZaam31PhBAVY+vJZF795TAp19URYd/qXo//yIiwwgyUugWlefPmREZGMnv27MJl9erVo0+fPkybNq3Y+uvWrWPQoEGcPXsWN7d7u0X236QF5Q5STsHKMXDhL/V5zY7QawY4+xu3LiGEUeXq9Hy87iQLdp0DZERYYRwP8vldqlnm8vPzOXDgAJ07dy6yvHPnzuzevbvEbVatWkXTpk355JNPqF69OrVr1+a///0vOTm3v1skLy+PjIyMIg9xGx61YPg66Pw+WNrCmc1qa8rB78H0uxcJIcpB7OVM+ny9qzCcDGsVzMoXWks4EWalVO3tKSkp6PV6vL2LTrPt7e1NUlJSiducPXuWP//8E1tbW1asWEFKSgpjxowhNTWV+fPnl7jNtGnTmDJlSmlKq9ostOqtx7W7wsrn4cLfsOpFiP4Nes4A5+rGrlAIUQEUReHHfQm8vzqavAID7g7WfNY/nA51vYxdmhClVqoWlBv+fe1SUZTbXs80GAxoNBp++uknmjVrxmOPPcYXX3zBwoULb9uKMmnSJNLT0wsf58+fL3E98S8etWD4eug0FbQ2cHqT2ppy6EdpTRGikkvNymfk9wd4e+Ux8goMtKvtyR/j20o4EWarVAHFw8MDrVZbrLUkOTm5WKvKDb6+vlSvXh1nZ+fCZfXq1UNRFC5cuFDiNjY2NlSrVq3IQ9wjCy20fglG74TqTSEvHX57ARYNgIxLxq5OCFEOdp9Oodv/7WDTictYay14u0d9Fg57CC8nGZBQmK9SBRRra2uaNGnCxo0biyzfuHEjrVq1KnGb1q1bc+nSJa5fvzkRW2xsLBYWFvj7S0fOcuNZR21NeXSK2ppyagN83QIO/iCtKUJUEjq9gY/+OMlT8/ZxOSOPmp4OrHihFSPahGBhIXfpCPNW6ks8EyZM4Ntvv2X+/PmcOHGCl19+mYSEBEaPHg2ol2eGDh1auP6TTz6Ju7s7zzzzDNHR0ezYsYNXX32V4cOHY2cns8KWK60ltBkPo3aAX6TamrJqLCzsDldijV2dEOIBxF/N4onZu5mz/QyKAoObBfL7i20I83O++8ZCmIFSD0oxcOBArl69ytSpU0lMTKRBgwasXbuWoKAgABITE0lISChc39HRkY0bN/Liiy/StGlT3N3dGTBgAO+//37ZHYW4M6+6MGIj7J0F26ZB/C6Y0xraTIA2L4OVNAMLYU6WH7zA2yuPkZWvx9nOio8eb0i3hr7GLkuIMiVD3Vc1afGw5hU4/c9lOvdQ6PElhLQzbl1CiLvKzNXx9spjrIxS+5M1C3Fj+sAI/FykNVqYJpmLR5SOokD0SvhjIly/rC6LeAo6vQcO7kYtTQhRsoMJaby0+BDnU3PQWmh4qWMtXugQilb6mggTVmEDtYlKQqOBsL7wwl/QdASggaif4KumELVIOtEKYUL0BoWvt56m/5w9nE/Nwd/VjqWjWjCuYy0JJ6JSkxYUAef/gt9fguRo9XlwW+gxHTxCjVqWEFVdYnoOLy+JYu/ZVAB6hvvxQd8GVLO1MnJlQtwbaUERDyagmXqnz6PvgqUdnNsJs1vB9k+gIM/Y1QlRJW04nkS3/9vJ3rOp2Ftr+ax/ODMGRUg4EVWGtKCIolLj1E60Zzarz91qQtePoHbnO28nhCgTuTo9H6w5wQ974wFoWN2ZGYMbE+LhYOTKhCg96SQrypaiwLFfYf0bNzvR1uoCXaeBe03j1iZEJRZ7OZMXFx0i5nImAKPa1eCVznWwtpTGbmGeJKCI8pGbATs+gb2zwVAAWmto+QK0/S/YOBq7OiEqDUVR+GlfAu/9M8mfh6MNXwwIp11tT2OXJsQDkYAiyteVWFj3+s3LPk6+6i3JDZ9Q7wgSQty3a9n5TPz1COuPq62V7Wt78ln/cDydbIxcmRAPTgKKKH+KAjF/wPpJkHZOXRbYCh77BHwaGrU0IczVvrNXGb8kisT0XKy0GiZ2rcvw1jKPjqg8JKCIiqPLhT0zYcfnUJADGgto8gw88hbYuxm7OiHMQoHewIwtp/lqyykMCoR4ODBzcGMaVJd5dETlIgFFVLz0C7DhLTi+Qn1u56qGlMhh6iSFQogSXUjLZvziKPbHpwHwRBN/pvQKw8FGfm9E5SMBRRhP3E51yPzk4+pzz3rQaSrU6iT9U4T4l7VHE3n91yNk5BbgaGPJB30b0DuiurHLEqLcSEARxqUvgP3zYduHkKP+VUhIO+j8PviGG7c2IUxATr6eqauj+fkvdab3iAAXZgxqTKC7vZErE6J8SUARpiEnDXZ+Dvvmgj4f0ECjgeqlH5cAY1cnhFGcTMrgxUWHOJV8HY0GRrevyYROtbHSytgmovKTgCJMS1o8bJ4Kx35Rn2ttoOUYaPMy2EonQFE1KIrCj3vjeW/NCfILDHg62TB9YAStQz2MXZoQFUYCijBNFw/AhskQ/6f63N4d2k+EpsNBK/OJiMrrWnY+r/1yhA3R6tgmHeqoY5u4O8rYJqJqkYAiTNeN8VM2Toarp9RlbjXViQnr9ZSOtKLS+ffYJq93q8fw1sFo5N+6qIIkoAjTp9fBwe9g20eQdUVdFtACHn0HgloZtzYhykCB3sDMLaeZKWObCFFIAoowH3mZsOv/YPdX6kBvADU7qh1pq0catzYh7tOlazmMXxzFX+dSAegX6c/U3jK2iRASUIT5ybgE2z+BQz+oExEC1O0BHd4E7/rGrU2IUlh3LImJvx4hPUeHo40l7/dpQJ/GMraJECABRZiz1LOw7WM4sgRQAI06CeHDk8C9prGrE+K2cnV63l8TzY971bFNwv2dmTG4MUHuDkauTAjTIQFFmL/kk7D1AzixSn2u0ULj/0D718DZ37i1CfEvpy5n8uLPhziZlAnAqHY1eKVzHawtZWwTIW4lAUVUHpeiYMv7cHqj+lxrDU1HQNsJ4Ohl1NKEUBSFxX+fZ8rvx8nVGfBwtOaLARG0q+1p7NKEMEkSUETlk7AXNr93cwwVK3toPgpavggO7satTVRJ6Tk63lh+lDVHEwFoW8uDLwZE4OkkY5sIcTsSUETlpChwdqvaonLxgLrMygEeGg6txkmLiqgwBxPSGPfzIS6k5WBpoeHVLnUY2bYGFhYytokQdyIBRVRuNwZ72/4RJB5Wl1naQpNnoPU4qOZn3PpEpWUwKMzZcYbPN8SiNygEutkzY3BjIgJcjF2aEGZBAoqoGhQFTm2E7R/Dxf3qMq01NB4CbcaDS6BRyxOVS3JGLi8vjWLX6asA9Ar344O+DXCylWkahLhXElBE1XLj0s/2TyFht7rMwhLCB6udad1qGLc+Yfa2xSTzytLDXM3Kx85Ky5TeYfRv4i/D1QtRShJQRNV17k+1RSVuh/pco4VGA6DtK+BRy7i1CbOTX2Dg0/Un+d/OOADq+VZj5uDGhHo5GrkyIcyTBBQhEvbBjk/g9Cb1ucYCwvpC65fAN9y4tQmzcC4li3GLD3HkQjoAw1oF83q3uthaaY1cmRDmSwKKEDdcPKBe+on94+ayGh3UoFLjYZk9WZTot6iLvLniGNfzCnCxt+KTfo3oHOZj7LKEMHsSUIT4t8Qj6qSEx1eAoleX+TRSg0r9PqCVSdwEZOUV8M6q4/xy4AIAzULc+L9BEfg62xm5MiEqBwkoQtxO2jnYMwsOfn9z9mSXQHXAt8b/AWt7o5YnjOf4pXRe/PkQZ69kYaGBcR1r8eIjtdDK2CZClBkJKELcTdZV+Ptb+GsuZKu3jWLnpo5O+9BIGZ22ClEUhe92n+PDtSfJ1xvwqWbL/w2KoHkN+TcgRFmTgCLEvcrPhqifYPdMuBavLrO0g8gh0GIMuIUYtz5RrtKy8nn1lyNsOnEZgEfrefPpE41wdbA2cmVCVE4SUIQoLX2BOnPyruk3R6fVWECdx6DF8xDUWjrUVjJ7z15l/OIokjJysdZa8Gb3egxtGSRjmwhRjiSgCHG/FEUdQ2XX/8GZzTeXezeEFqOhwRNgZWu8+sQD0xsUZmw+xcwtpzAoUMPTgZmDGxPm52zs0oSo9CSgCFEWkk/CvjlwePHNDrX2HtB0ODw0ApzktlNzk5iew0uLo/grLhWAJ5r4M6VXGA42cheXEBVBAooQZSk7FQ5+B399Cxnq7adYWEGDx9XLP36NjVufuCcboy/z6i+HuZatw9HGkg/6NqB3RHVjlyVElSIBRYjyoC+Ak7/D3tlwft/N5QEt1Ms/dXvKeComKFen56M/TrJw9zkAGlZ3ZubgxgR7OBi3MCGqIAkoQpS3iwfVyz/HloNBpy5z8oMmwyByKFTzNWp5QnXmynXGLjrEicQMAEa2DeHVLnWxtrQwcmVCVE0SUISoKJlJ8Pc82D8fslPUZRaWULc7NB0BIe3k7h8jUBSFZQcu8M5vx8nR6XF3sOazAeF0qONl7NKEqNIkoAhR0QryIHoV7J8HCXtuLveorXaqDR8Mdi5GK68qyczV8dbKY/wWdQmA1qHufDkgAq9qcveVEMYmAUUIY7p8XG1VObIE8q+ryyztoOET6t0/0qm23By5cI0Xfz5E/NVstBYaJnSqzej2NWW4eiFMhAQUIUxBXqYaUv6eD8nHby73i1SDStjjMvdPGTEYFOb9Gccn60+i0ytUd7FjxuAImgS5Gbs0IcQtJKAIYUoURb3r5+9vIfo30Oery22qQcP+aqdavwijlmjOUq7n8crSw2yPvQLAYw19mPZ4I5ztrIxcmRDi3ySgCGGqrl+BqB9h/4Kbc/8A+DSEyKfVy0B2rsarz8zsOp3C+CVRXMnMw8bSgnd6hjG4WYAMVy+EiZKAIoSpMxjg3A44+D2c+P1mq4qlLdTrpU5WGNQGLOR22JLo9Aa+3BjL7O1nUBSo5eXIV09GUsfHydilCSHuQAKKEOYkOxWOLFXDyq19VVxD1KAS/qSMq3KL86nZjFt8iEMJ1wAY3CyQyT3qY2etNW5hQoi7epDP7/v6c23WrFmEhIRga2tLkyZN2Llz5z1tt2vXLiwtLYmIiLiftxWicrB3U0eifX4XjNyiDvZm7QRpcbB5KnwZBosGqbcxF+QZu1qjWnMkkcdm7ORQwjWcbC35+slIpj3eUMKJEFVAqVtQlixZwpAhQ5g1axatW7dm7ty5fPvtt0RHRxMYGHjb7dLT04mMjCQ0NJTLly8TFRV1z+8pLSii0svPguMr1VaV83tvLrdzhQb91HFVqjepMoPA5eTrmbr6OD//dR6AyEAX/m9QYwLc5C4oIcxJhV7iad68OZGRkcyePbtwWb169ejTpw/Tpk277XaDBg2iVq1aaLVaVq5cKQFFiNu5Eqt2rD2yFDITby53rwXhg6DRQHAJMF595SwmKZOxiw5yKvk6Gg2Mebgm4x+tjZVW+ucIYW4q7BJPfn4+Bw4coHPnzkWWd+7cmd27d992uwULFnDmzBneeeede3qfvLw8MjIyijyEqDI8a0OnqfDycfjPcmg4QB347eop2PIeTG8I3/WEqEWQd93Y1ZYZRVH4cW88vb76k1PJ1/F0suHHEc15tUtdCSdCVEGlmoo1JSUFvV6Pt7d3keXe3t4kJSWVuM2pU6d4/fXX2blzJ5aW9/Z206ZNY8qUKaUpTYjKx0ILoR3VR16mOqbK4cVwbifE7VAfa15R7wIKH6TOA2Rhnn0z0rN1TPz1COuOq/+PPFzHk8/6h+PhaGPkyoQQxnJfc8X/e8wBRVFKHIdAr9fz5JNPMmXKFGrXrn3P+580aRITJkwofJ6RkUFAQOVt0hbirmycoPF/1EdavHr55/DPkHoGjixWH44+ENZXHVvFjPqr7D+XykuLo7h4LQcrrYaJXesyvHUIFjJcvRBVWqn6oOTn52Nvb8+yZcvo27dv4fKXXnqJqKgotm/fXmT9a9eu4erqilZ78686g8GAoihotVo2bNjAI488ctf3lT4oQpRAUeDCfji8CI4th9xrN19zDYYGT6gj13rVNVaFd6Q3KMzaeprpm0+hNygEu9szY3BjGvm7GLs0IUQZqfBOsk2aNGHWrFmFy+rXr0/v3r2LdZI1GAxER0cXWTZr1iy2bNnCL7/8QkhICA4ODnd9TwkoQtxFQT6c2QJHl0HMWtBl33zNu4F6J1CDfuAaZLwab5GUnsv4JYfYezYVgD4RfrzftyGONvfVqCuEMFEP8vld6v8NJkyYwJAhQ2jatCktW7bkm2++ISEhgdGjRwPq5ZmLFy/y/fffY2FhQYMGDYps7+Xlha2tbbHlQogHYGkNdbqqj/wsiPkDjv4CpzfB5WPqY/MUCGiutqyE9QVHT6OUujH6Mq/+cphr2TrsrbW836cBj0f6G6UWIYTpKnVAGThwIFevXmXq1KkkJibSoEED1q5dS1CQ+pdZYmIiCQkJZV6oEOIeWTuo/VAaPqGOWnvid7Vl5dyf6iSG5/fBuokQ3Abq91E72VZAWMnV6Zm29gTf7VHnJGpQvRozB0cS4nH3VlQhRNUjQ90LUVVkJMLx5WrLyqWDN5drLCCoNYT1gbo9wcn7tru4X6eTMxm76BAnkzIBeLZNCK92rYONpXnedSSEuDcyF48QonRS49TblqNXwqVDt7yguRlW6vV64LCiKApL95/n3VXR5Oj0uDtY81n/cDrU9Xqg/QohzIMEFCHE/UuLvxlWLh645QUNBLX65zJQz1JPYJieo+ONFUdZc0QdDbdNqAdfDAjHq5ptmZUuhDBtElCEEGXjWoI6SWH0Srjwd9HX/B+Cuj3Uh0foHXdzID6NlxYf4kJaDpYWGl7pXIdR7WrI2CZCVDESUIQQZe/aeTixSp3E8MJfRV/zrAt1u6thxa9x4aBweoPCnO1n+GJjLHqDQoCbHTMGNaZxoGvF1y+EMDoJKEKI8pWRqI6vcnK1OsS+oeDma9WqQ93upAZ0Ytxue/6MSwegZ7gfH/RtQDVbKyMVLYQwNgkoQoiKk3MNTm1Uw8qpjaDLKnzpmuLAdiUSj6aP06rzE2hs5fdViKpMAooQwihyc7L4ZdmPWMau5VHtQTw0t8w8rrVWx1qp3Q1qdzGZUWyFEBVHAooQosLFXs7kxUWHiLmsjm0ysnUgr4alYx27FmL/gNSzRTfwqq8GldrdwL+p2c68LIS4dxJQhBAVRlEUftqXwHuro8krMODhqI5t8nAdr1tXgpRTELtOfSTsBUV/83V7d6jVGWp3hZqPgFwKEqJSkoAihKgQ17LzmfjrEdYfvwxA21oefD4gHC+nu4xtkp0KpzerLSunNkFe+s3XLKwgqCWEdoJandQ7hDRyO7IQlYEEFCFEudt79iovL4kiMT0XK62G17rUZUSbkNKPbaLXqS0qN1pXrp4u+no1f6j1KIQ+CiHtpXVFCDMmAUUIUW4K9AZmbD7FV1tPY1AgxMOBGYMa09DfuWzeIOU0nN6o3hF07k/Q5918zcISAluqYaVWJ7Ufi7SuCGE2JKAIIcrF+dRsxi+J4kB8GgBPNPFnSq8wHGxKPRH6vcnPhvhdalg5vbF4R1snPwjtqD5C2oO9W/nUIYQoExJQhBBlbtXhS7y5/CiZeQU42ljyQd8G9I6oXrFFXD0Dpzepj7idUJBzy4sadRTbmo9AzQ7g3wwsrSu2PiHEHUlAEUKUmet5Bbzz23F+PXgBgMaBLswY1JgAN3vjFqbL+ad1ZROc3QpXThZ93cpBHXelZgeo0QE868jlICGMTAKKEKJMRJ2/xkuLDxF/NRsLDYztEMq4jrWw1FoYu7TiMi7B2W1wZov6NetK0ded/G6GlRrtwdGrpL0IIcqRBBQhxAPRGxTm7jjDFxtiKTAo+DnbMn1QY5qFmEkfD4MBko/Dma1qYEnYAwW5RdfxrAch7dRHcGuwkwkMhShvElCEEPctMT2HCUsOs+fsVQC6N/Tlw74NcbY340n+dDnqrcxntqiXg5KOAbf+V6cB3/B/Akt7CGwBNo7GqlaISksCihDivqw7lsTry49wLVuHvbWWd3uF0b+JP5rK1ncjO1W9hTluh/pIiSn6uoUlVG96s4XF/yGwusvgc0KIu5KAIoQolZx8Pe+tiWbRvgQAGlZ35v8GRVDDs4q0ImQkwrmdELcdzu6A9ISir2ut1cAS3BqCWkNAM7B2ME6tQpgxCShCiHt2/FI6434+xJkrWQCMal+DVzrVwdrSBDvCVpS0czdbV+J2wPXLRV+3sAS/yH8CSxsIbA42TkYpVQhzIgFFCHFXBoPC/F1xfLIuhny9AS8nG74YEEGbWh7GLs20KIo6/kr8n3Bul3prc8bFoutotGoflhuBJaCZDBonRAkkoAgh7igpPZf/LjvMn6dTAHi0njefPNEINwcZ2OyuFAWuxath5dyfanC5llB8Pa/6amfbwJbqV+cAGYdFVHkSUIQQt3VrR1hbKwsm9whjcLOAytcRtiJdOw/xu9WwEr+7+ISHANWq3xJYWoJXPbDQVnytQhiRBBQhRDFZeQW8tzqaxX+fB6BB9WpMH9iYUK8q0hG2Il2/Auf3qrc2J+yBxMNgKCi6jo2zeikosDkENFf7tMitzaKSk4AihCji8PlrjF8SRVxKFhoNjGpXkwmdalftjrAVKT8LLh5QA0v8brjwN+RfL7qOxgK8G6ihxb+Z+tU1WC4LiUpFAooQAlBHhJ2z/QxfblRHhPWpZssXA8NpVVM6whqVvgAuH1NbV87vg/N/Q8aF4us5eN4MKwHN1MkQrewqvl4hyogEFCEEF6/l8PKSKP6KSwXgsYY+fNi3IS720hHWJKVfhAt/qWHlwl9wKQoMuqLrWFiCT0N1TBb/pupXtxpgIS1hwjxIQBGiivv98CXeWHGUzNwC7K21TOkVxhOVcUTYykyXq/ZdufDXP60sfxUfjwXA1hmqN7kltDQBB2khE6ZJAooQVVRGro53fzvO8kPqOB3hAS7838AIgj1k1FOzpyjq7cwX98OFA+rXxMPFJ0EEcAm62cJSvYna6mJtX/E1C/EvElCEqIL+ikvl5SVRXLyWg4UGXugQyriOtbDSSvN/paXXqX1ZLh64GVpSYouvp9GqtzX7Nb758G4AlnK5T1QsCShCVCH5BQa+3BTLnO1nUBQIcLPjywERNA2WkUyrpJxrcOngLaHlAGQlF19Paw3eYertzX6NoXokeNQBrWWFlyyqDgkoQlQRpy5nMn5JFMcvZQDQv4k/k3vWx8nWysiVCZOhKJBxCS4d+udxUP2ak1Z8XSt7tWXFL0Idut83HDzrglb+PYmyIQFFiEpOURS+232OaX+cJK/AgKu9FdMeb0jXBr7GLk2YA0VRJ0QsDCxR6iM/s/i6Whu1peVGYPENV4fxt7Kt4KJFZSABRYhK7HKGOo/OzlPqPDrtanvy2RON8KomHxjiARgM6hD9iYchMeqfr4chL6P4uhaW4FkP/MLBp5HaCde7AdjK/8fiziSgCFFJ/XE0kUkrjnItW4eNpQVvPFaPoS2D5PZhUT4MBrh27mZYuRSlfs1JLXl912A1rNwILT4N1TmI5N+n+IcEFCEqmcxcHVN+j+aXA+poo+o8OhGEejkZuTJR5SgKpF+42dKSdAySjpY8Ei6AnWvR0OLdADxqyx1EVZQEFCEqkb/PqbcPX0jLQaOB59vXZPyjMo+OMDHZqWpQufVx5SQo+uLrWliqdwx5h/3zaKB+dfKR1pZKTgKKEJVAXoGeLzbE8s3OsygK+Lva8eXACB6S24eFudDlqiHl1tBy+TjkpZe8vp1b0cDiHabeRSSDzFUaElCEMHPHL6UzYclhYi6rd1XI7cOi0rhxiejycXWQucvH1cfVU6AYSthAo/Zt8aoP3vXVAee86oN7qNz+bIYkoAhhpgr0BubuOMv0TbHo9AoejtZ82LchncN8jF2aEOVLlwNXYm4GlhvhJTul5PUtrMCj1j+B5Z/Q4lVPHebfQluxtYt79iCf3zKEoBBGci4liwlLoziYcA2ALmHefNi3Ie6ONsYtTIiKYGWnDhDnF1F0+fUrkBwNySdu+XpCHbMlOVp93MrSTg0unnXBs44aWjzrqq0wElzMmgQUISqYoij8tC+BD9acIEenx8nGknd7hfF4ZHW5fVgIR09wbA812t9cduMyUZHQchyuxEJBDiQdUR+30tqodw951lEDi1ddtaOuW4hcKjITElCEqEBJ6bm89usRdsReAaBVTXc+7R9OdRc7I1cmhAnTaMAlQH3U7nxzuUGvjpB75aT6SP7na0qsOuvz5aPq41YWVuBW459WlzpqaPGopYYZG8cKPSxxZ9IHRYgK8lvURd5eeYyM3AJsLC14vVtdnm4ZjIWFtJoIUaYMergWr/ZxKQwuJyDlFOiyb79dNf9bgss/ocW9ltwO/QCkk6wQJiwtK5+3fzvG6iOJADTyd+aLAeEy6JoQFc1ggIyLkBKjhpUrMWprS0osZF25/XbWTuBeUw0t7rXAI1T96h4qt0TfhQQUIUzUxujLTFp+lJTreWgtNLz4SCgvdAjFSiuDrglhUrJT1dCSEnNLcDmltsSUeDv0P6r5Fw0s7qHgXgOcA0ErvSgkoAhhYtKzdUz5/TjLD10EINTLkc/7hxMe4GLcwoQQpVOQB6lx6rgtKafUCRZTTqnPc9Juv52FlXonkXuo2vriXlP93q0mOPmCRdX4I0VuMxbChGw9mczry49wOSMPCw2MbFeDlx+tja2V3PIohNmxtFHvAPKqW/y1rKu3BJdTcPWM+kg9C/q8f5adKr6dlb3aUbekRxUKL3cjAUWIMpKRq+P91dEs3a9OolbDw4FP+4fTJMjVyJUJIcqFg7v6CGxRdLnBoE6mePWM2uKSelb9evWMeteRLvufgemOFd+npS24hvwTWEKKhhdn/yo1tst9BZRZs2bx6aefkpiYSFhYGNOnT6dt27Ylrrt8+XJmz55NVFQUeXl5hIWF8e6779KlS5cHKlwIU7Ij9goTfz1CYnouGg2MaB3Cf7vUkVYTIaoiCwtwCVQfNTsUfU2vg2sJN4PLrY9rCert0VdOqI9i+7VU9+kaol4+cgu5+b1rcKW7TbrUAWXJkiWMHz+eWbNm0bp1a+bOnUu3bt2Ijo4mMDCw2Po7duygU6dOfPjhh7i4uLBgwQJ69uzJvn37aNy4cZkchBDGcj2vgA/XnmDRvgQAgtzt+ax/uEzwJ4QomdbqZp+Uf9MXQPr5W0JL3M3v0+JAn3/zeUkcvP4VXILUqQBcg83y0lGpO8k2b96cyMhIZs+eXbisXr169OnTh2nTpt3TPsLCwhg4cCCTJ0++p/Wlk6wwRbtPp/DqL0e4eC0HgGGtgnmtax3sreXKqRCijBkMkHlJDS1pceqlolu/v1OHXQCt9T+tOkFqcHENLvq9Xflciq6wTrL5+fkcOHCA119/vcjyzp07s3v37nvah8FgIDMzEze32/+FmZeXR15eXuHzjIyM0pQpRLnKyivg43Un+X5PPAD+rnZ8+kQ4LWu6G7kyIUSlZWGh9kFx9oeQErpU5FxTw0rqP4ElLQ7S4tXbpK+dV1tfrp5WHyWxcYbun0Oj/uV5FKVSqoCSkpKCXq/H29u7yHJvb2+SkpLuaR+ff/45WVlZDBgw4LbrTJs2jSlTppSmNCEqxM5TV5i0/CgX0tRWk/+0CGRSt3o42EiriRDCiOxcwK4x+JXQdUJfoA5Qdy3+n/ASX/T7rGTISwcb0xo88r7+V/33hGaKotzTJGc///wz7777Lr/99hteXl63XW/SpElMmDCh8HlGRgYBAQH3U6oQZSI9R8cHa27eoePvasdHjzeiTS0PI1cmhBB3obX851JOEIS0K/56fpbaQbda9Yqv7Q5KFVA8PDzQarXFWkuSk5OLtar825IlSxgxYgTLli3j0UcfveO6NjY22NjIlPPCNGyMvsybK46SnJmHRgNPtwzm1S51pNVECFE5WDuAVz1jV1FMqbr0Wltb06RJEzZu3Fhk+caNG2nVqtVtt/v5558ZNmwYixYtonv37vdXqRAV7Or1PF78+RAjv99PcmYeNTwcWDqqJe/2CpNwIoQQ5azU/8tOmDCBIUOG0LRpU1q2bMk333xDQkICo0ePBtTLMxcvXuT7778H1HAydOhQ/u///o8WLVoUtr7Y2dnh7OxchociRNlQFIXfjyTy7qrjpGblo7XQMLJtDcY/WkvGNRFCiApS6oAycOBArl69ytSpU0lMTKRBgwasXbuWoKAgABITE0lISChcf+7cuRQUFPDCCy/wwgsvFC5/+umnWbhw4YMfgRBl6HJGLm+uOMamE5cBqOvjxKdPhNPQX8K0EEJUJJksUAjUVpOl+8/z/poTZOYWYKXVMLZDLZ5/uCbWluY1uJEQQpgKmSxQiAcQfzWLN1cc48/TKQCE+zvzyRPh1PExrVvuhBCiKpGAIqosnd7AtzvjmL4plrwCAzaWFrzSuTbDW4dgqZVWEyGEMCYJKKJKOpSQxqTlRzmZlAlAq5rufNC3ISEeDkauTAghBEhAEVVMZq6Oz9bH8P3eeBQFXO2teKt7fR6PrH5Pgw0KIYSoGBJQRJWx/ngS7/x2nKSMXAAej6zOW93r4+ZgbeTKhBBC/JsEFFHpJaXn8s6qY6w/rt46HORuzwd9Gsow9UIIYcIkoIhKS29Q+GlfPJ+si+F6XgGWFhqea1eDcR1lwDUhhDB1ElBEpXQiMYNJy48Sdf4aABEBLnzUryF1fWQcHSGEMAcSUESlkpmrY/qmUyzcfQ69QcHRxpLXutbhqeZBaC2kE6wQQpgLCSiiUlAUhVWHL/HBmhMkZ+YB0DXMh3d7heHjbGvk6oQQQpSWBBRh9k4nZ/L2yuPsOXsVUDvBTukVxsN1vIxcmRBCiPslAUWYray8AmZsOcW8nXEUGBRsLC14oUMoz7WrIZ1ghRDCzElAEWZHURTWHUti6upoEtPVMU0erefFOz3DCHCzN3J1QgghyoIEFGFW4lKymPzbMXaeUif283e1492eYTxa39vIlQkhhChLElCEWcjJ1/P11tN8s+Ms+XoD1loLRrevwZgOoXI5RwghKiEJKMKkKYrC70cS+WjtCS79czmnfW1PpvQKI1gm9hNCiEpLAoowWYfPX2Pq6mgOxKcBUN3Fjrd71KdLmLdM7CeEEJWcBBRhcpLSc/lk/UmWH7wIgJ2VljEP12Sk3J0jhBBVhgQUYTJydXr+t+Mss7adIUenB9QZh1/rUlcGWxNCiCpGAoowOkVRWH0kkY/+OMnFazkARAa6MLlnGBEBLsYtTgghhFFIQBFGdeTCNab+Hs3+f/qZ+Dnb8vpj9ejZyFf6mQghRBUmAUUYRVJ6Lp+uj+HXgxcAtZ/J8w/XZGTbGthZSz8TIYSo6iSgiAqVnq1j9vYzLNgVR16BAYDHG1fn1a518HW2M3J1QgghTIUEFFEhcnV6Fu4+x6ytp8nILQCgaZArb3avR+NAVyNXJ4QQwtRIQBHlqkBvYNmBC0zfFMvljDwAans78lqXunSs5yX9TIQQQpRIAoooFzcm9Pt0Qwxnr2QB6kBrL3eqTd/G1dFaSDARQghxexJQRJnbfTqFj9ed5PCFdABc7a0Y+0gt/tMiEBtL6QArhBDi7iSgiDJz7GI6H687WTjTsL21lmfb1mBk2xCcbK2MXJ0QQghzIgFFPLDjl9KZufk0644nAWCl1fBks0DGPlILTycbI1cnhBDCHElAEfft8PlrzNxyik0nkguX9Y7w45VOdQh0tzdiZUIIIcydBBRRagfi05ix+RTbY68AoNFAz0Z+jH0klNreTkauTgghRGUgAUXcs31nrzJjyyl2nb4KgNZCQ+8IP17oEEpNT0cjVyeEEKIykYAi7khRFHafucqMzafYF5cKgKWFhn6R/ozpUJMgdwcjVyiEEKIykoAiSqQoCttjrzBzy2kO/DORn5VWw4CmAYxuX5MAN+ljIoQQovxIQBFF5Or0/BZ1kfl/niPmciYA1pYWPNkskFHta8h8OUIIISqEBBQBQHJGLj/ujeenfQlczcoH1HFMBjcLZFS7GnhVszVyhUIIIaoSCShV3LGL6czfFcfvhy+h0yuAOiT9062CGNg0EGd7GWBNCCFExZOAUgXpDQqbTlxm3p9x/PVPx1eAJkGuDG8dQpcwbyy1FkasUAghRFUnAaUKyczVsXT/BRbujuN8ag6g3pHzWENfhrcJISLAxbgFCiGEEP+QgFLJKYrCgfg0lu2/wOojl8jK1wPgbGfFk80DGdoySDq+CiGEMDkSUCqpyxm5/HrwAr/sv8DZlKzC5TU9HRjeJoTHG/tjZy0zCwshhDBNElAqkbwCPZuik1l24Dw7Yq9gUPu8Ymel5bGGvvRv6k+zYDcsLDTGLVQIIYS4CwkoZk5RFI5fymDZ/vP8dvgS17J1ha89FOxK/yYBPNbIF0cbOdVCCCHMh3xqmanzqdmsP57ELwcucDIps3C5TzVb+jWpzhNNAgjxkGHohRBCmCcJKGbiRkvJhuNJbIi+XCSUWGst6BTmTf8m/rSt5YlWLuEIIYQwcxJQTJhOb2Df2VQ2RCexKfoyl9JzC1+z0MBDwW50b+RLr3A/XOytjVipEEIIUbYkoJiYzFwd22OvsOH4ZbbGJJOZW1D4mp2Vlna1PehU34dH6nrh5iChRAghROUkAcXIMnJ1RCVcY398GvvPpfL3udTCIecBPByt6VjXm071vWlTywNbK7k1WAghROUnAaUCKYrChbQcDsSnsT8+lf3n0oi5nImiFF0vxMOBzvXVUNI40FX6lAghhKhy7iugzJo1i08//ZTExETCwsKYPn06bdu2ve3627dvZ8KECRw/fhw/Pz9ee+01Ro8efd9Fm4u8Aj0nEzPZH5/GgfhUDsSncTkjr9h6AW52NA1yIzLIlZY13Kjp6YhGI6FECCFE1VXqgLJkyRLGjx/PrFmzaN26NXPnzqVbt25ER0cTGBhYbP24uDgee+wxRo4cyY8//siuXbsYM2YMnp6e9OvXr0wOwpjSc3QkXM0mPjWL+KvZhd8nXM0mMSO3WOuIpYWGsOrONAl0pWmwK02DXPGqZmuc4oUQQggTpVGUf3+E3lnz5s2JjIxk9uzZhcvq1atHnz59mDZtWrH1J06cyKpVqzhx4kThstGjR3P48GH27NlzT++ZkZGBs7Mz6enpVKtWrTTl3tG17HwycwvIKzCQV6Anv8BAfoGBvFu/6vXk6Qzk6w3k6Qyk5+iIT80m4WoW8anZRQZGK4mznRWRgS40DXajSZAr4f4uMsS8EEKIKuFBPr9L1YKSn5/PgQMHeP3114ss79y5M7t37y5xmz179tC5c+ciy7p06cK8efPQ6XRYWVkV2yYvL4+8vJuXQjIyMkpT5j17c8Ux1hxNfOD9eDjaEOhmR5C7A4Fu9gS5q49ANwc8HK3lco0QQghRSqUKKCkpKej1ery9vYss9/b2JikpqcRtkpKSSly/oKCAlJQUfH19i20zbdo0pkyZUprS7outlRY7Ky3WlhZYW1pgU/hVW/jcxtICa60FNlbqV0dbSwLd1PChhhB7HGQYeSGEEKJM3dcn679bBBRFuWMrQUnrl7T8hkmTJjFhwoTC5xkZGQQEBNxPqXf0+YBwPh8QXub7FUIIIcSDKVVA8fDwQKvVFmstSU5OLtZKcoOPj0+J61taWuLu7l7iNjY2NtjY2JSmNCGEEEJUIhalWdna2pomTZqwcePGIss3btxIq1atStymZcuWxdbfsGEDTZs2LbH/iRBCCCFEqQIKwIQJE/j222+ZP38+J06c4OWXXyYhIaFwXJNJkyYxdOjQwvVHjx5NfHw8EyZM4MSJE8yfP5958+bx3//+t+yOQgghhBCVSqn7oAwcOJCrV68ydepUEhMTadCgAWvXriUoKAiAxMREEhISCtcPCQlh7dq1vPzyy3z99df4+fkxY8aMSjEGihBCCCHKR6nHQTGG8hoHRQghhBDl50E+v0t9iUcIIYQQorxJQBFCCCGEyZGAIoQQQgiTIwFFCCGEECZHAooQQgghTI4EFCGEEEKYHAkoQgghhDA5ElCEEEIIYXIkoAghhBDC5JR6qHtjuDHYbUZGhpErEUIIIcS9uvG5fT+D1ptFQMnMzAQgICDAyJUIIYQQorQyMzNxdnYu1TZmMRePwWDg0qVLODk5odFo7rhuRkYGAQEBnD9/vtLP2yPHWnlVpeOVY628qtLxyrGWTFEUMjMz8fPzw8KidL1KzKIFxcLCAn9//1JtU61atUr/j+QGOdbKqyodrxxr5VWVjleOtbjStpzcIJ1khRBCCGFyJKAIIYQQwuRUuoBiY2PDO++8g42NjbFLKXdyrJVXVTpeOdbKqyodrxxr2TOLTrJCCCGEqFoqXQuKEEIIIcyfBBQhhBBCmBwJKEIIIYQwORJQhBBCCGFyzC6gzJo1i5CQEGxtbWnSpAk7d+684/rbt2+nSZMm2NraUqNGDebMmVNBlT6YadOm8dBDD+Hk5ISXlxd9+vQhJibmjtts27YNjUZT7HHy5MkKqvr+vPvuu8Vq9vHxueM25npeAYKDg0s8Ty+88EKJ65vTed2xYwc9e/bEz88PjUbDypUri7yuKArvvvsufn5+2NnZ8fDDD3P8+PG77vfXX3+lfv362NjYUL9+fVasWFFOR3Dv7nSsOp2OiRMn0rBhQxwcHPDz82Po0KFcunTpjvtcuHBhiec6Nze3nI/m7u52bocNG1as7hYtWtx1v+Z2boESz5FGo+HTTz+97T5N9dzey2eNsX5vzSqgLFmyhPHjx/Pmm29y6NAh2rZtS7du3UhISChx/bi4OB577DHatm3LoUOHeOONNxg3bhy//vprBVdeetu3b+eFF15g7969bNy4kYKCAjp37kxWVtZdt42JiSExMbHwUatWrQqo+MGEhYUVqfno0aO3XdeczyvA33//XeRYN27cCED//v3vuJ05nNesrCzCw8P56quvSnz9k08+4YsvvuCrr77i77//xsfHh06dOhXOt1WSPXv2MHDgQIYMGcLhw4cZMmQIAwYMYN++feV1GPfkTseanZ3NwYMHefvttzl48CDLly8nNjaWXr163XW/1apVK3KeExMTsbW1LY9DKJW7nVuArl27Fql77dq1d9ynOZ5boNj5mT9/PhqNhn79+t1xv6Z4bu/ls8Zov7eKGWnWrJkyevToIsvq1q2rvP766yWu/9prryl169YtsmzUqFFKixYtyq3G8pKcnKwAyvbt22+7ztatWxVASUtLq7jCysA777yjhIeH3/P6lem8KoqivPTSS0rNmjUVg8FQ4uvmel4BZcWKFYXPDQaD4uPjo3z00UeFy3JzcxVnZ2dlzpw5t93PgAEDlK5duxZZ1qVLF2XQoEFlXvP9+vexluSvv/5SACU+Pv626yxYsEBxdnYu2+LKQUnH+/TTTyu9e/cu1X4qy7nt3bu38sgjj9xxHXM5t//+rDHm763ZtKDk5+dz4MABOnfuXGR5586d2b17d4nb7Nmzp9j6Xbp0Yf/+/eh0unKrtTykp6cD4Obmdtd1GzdujK+vLx07dmTr1q3lXVqZOHXqFH5+foSEhDBo0CDOnj1723Ur03nNz8/nxx9/ZPjw4XedCNMcz+ut4uLiSEpKKnLubGxsaN++/W1/h+H25/tO25ii9PR0NBoNLi4ud1zv+vXrBAUF4e/vT48ePTh06FDFFFgGtm3bhpeXF7Vr12bkyJEkJyffcf3KcG4vX77MmjVrGDFixF3XNYdz++/PGmP+3ppNQElJSUGv1+Pt7V1kube3N0lJSSVuk5SUVOL6BQUFpKSklFutZU1RFCZMmECbNm1o0KDBbdfz9fXlm2++4ddff2X58uXUqVOHjh07smPHjgqstvSaN2/O999/z/r16/nf//5HUlISrVq14urVqyWuX1nOK8DKlSu5du0aw4YNu+065npe/+3G72lpfodvbFfabUxNbm4ur7/+Ok8++eQdJ1erW7cuCxcuZNWqVfz888/Y2trSunVrTp06VYHV3p9u3brx008/sWXLFj7//HP+/vtvHnnkEfLy8m67TWU4t9999x1OTk48/vjjd1zPHM5tSZ81xvy9NYvZjG/1778yFUW541+eJa1f0nJTNnbsWI4cOcKff/55x/Xq1KlDnTp1Cp+3bNmS8+fP89lnn9GuXbvyLvO+devWrfD7hg0b0rJlS2rWrMl3333HhAkTStymMpxXgHnz5tGtWzf8/Pxuu465ntfbKe3v8P1uYyp0Oh2DBg3CYDAwa9asO67bokWLIh1LW7duTWRkJDNnzmTGjBnlXeoDGThwYOH3DRo0oGnTpgQFBbFmzZo7fnib87kFmD9/Pk899dRd+5KYw7m902eNMX5vzaYFxcPDA61WWyx9JScnF0tpN/j4+JS4vqWlJe7u7uVWa1l68cUXWbVqFVu3bsXf37/U27do0cKkEvq9cHBwoGHDhretuzKcV4D4+Hg2bdrEs88+W+ptzfG83rgzqzS/wze2K+02pkKn0zFgwADi4uLYuHHjPU1NfysLCwseeughszvXoLb8BQUF3bF2cz63ADt37iQmJua+fodN7dze7rPGmL+3ZhNQrK2tadKkSeEdDzds3LiRVq1albhNy5Yti62/YcMGmjZtipWVVbnVWhYURWHs2LEsX76cLVu2EBIScl/7OXToEL6+vmVcXfnKy8vjxIkTt63bnM/rrRYsWICXlxfdu3cv9bbmeF5DQkLw8fEpcu7y8/PZvn37bX+H4fbn+07bmIIb4eTUqVNs2rTpvsKzoihERUWZ3bkGuHr1KufPn79j7eZ6bm+YN28eTZo0ITw8vNTbmsq5vdtnjVF/b++5O60JWLx4sWJlZaXMmzdPiY6OVsaPH684ODgo586dUxRFUV5//XVlyJAhheufPXtWsbe3V15++WUlOjpamTdvnmJlZaX88ssvxjqEe/b8888rzs7OyrZt25TExMTCR3Z2duE6/z7eL7/8UlmxYoUSGxurHDt2THn99dcVQPn111+NcQj37JVXXlG2bdumnD17Vtm7d6/So0cPxcnJqVKe1xv0er0SGBioTJw4sdhr5nxeMzMzlUOHDimHDh1SAOWLL75QDh06VHjnykcffaQ4Ozsry5cvV44ePaoMHjxY8fX1VTIyMgr3MWTIkCJ35u3atUvRarXKRx99pJw4cUL56KOPFEtLS2Xv3r0Vfny3utOx6nQ6pVevXoq/v78SFRVV5Hc4Ly+vcB//PtZ3331XWbdunXLmzBnl0KFDyjPPPKNYWloq+/btM8YhFnGn483MzFReeeUVZffu3UpcXJyydetWpWXLlkr16tUr3bm9IT09XbG3t1dmz55d4j7M5dzey2eNsX5vzSqgKIqifP3110pQUJBibW2tREZGFrnt9umnn1bat29fZP1t27YpjRs3VqytrZXg4ODb/mMyNUCJjwULFhSu8+/j/fjjj5WaNWsqtra2iqurq9KmTRtlzZo1FV98KQ0cOFDx9fVVrKysFD8/P+Xxxx9Xjh8/Xvh6ZTqvN6xfv14BlJiYmGKvmfN5vXFL9L8fTz/9tKIo6i2L77zzjuLj46PY2Ngo7dq1U44ePVpkH+3bty9c/4Zly5YpderUUaysrJS6deuaRDi707HGxcXd9nd469athfv497GOHz9eCQwMVKytrRVPT0+lc+fOyu7duyv+4Epwp+PNzs5WOnfurHh6eipWVlZKYGCg8vTTTysJCQlF9lEZzu0Nc+fOVezs7JRr166VuA9zObf38lljrN9bzT8FCiGEEEKYDLPpgyKEEEKIqkMCihBCCCFMjgQUIYQQQpgcCShCCCGEMDkSUIQQQghhciSgCCGEEMLkSEARQgghhMmRgCKEEEIIkyMBRQhRKDg4mOnTpxu7DCGEkIAihCkYNmwYGo0GjUaDlZUVNWrU4L///S9ZWVlGrUuj0bBy5Uqj1mDK5OcjRPmxNHYBQghV165dWbBgATqdjp07d/Lss8+SlZXF7NmzjV2aSdLr9Wg0GiwszP/vLJ1OZ1YzcQtREcz/N1uISsLGxgYfHx8CAgJ48skneeqppwr/OlcUhU8++YQaNWpgZ2dHeHg4v/zyS+G227ZtQ6PRsHnzZpo2bYq9vT2tWrUiJiamcJ0zZ87Qu3dvvL29cXR05KGHHmLTpk23rSc4OBiAvn37otFoCA4O5ty5c1hYWLB///4i686cOZOgoCBuN7VXcHAw7733Hk8++SSOjo74+fkxc+bMIut88cUXNGzYEAcHBwICAhgzZgzXr18vfH3hwoW4uLiwevVq6tevj42NDfHx8fz999906tQJDw8PnJ2dad++PQcPHiyyb41Gw9y5c+nRowf29vbUq1ePPXv2cPr0aR5++GEcHBxo2bIlZ86cKbLd77//TpMmTbC1taVGjRpMmTKFgoKC2/587mW7G/XMmTOH3r174+DgwPvvv3/b8yBElXU/sx8KIcrW008/rfTu3bvIshdffFFxd3dXFEVR3njjDaVu3bqF07UvWLBAsbGxUbZt26Yoys3ZV5s3b65s27ZNOX78uNK2bVulVatWhfuLiopS5syZoxw5ckSJjY1V3nzzTcXW1rbIFPJBQUHKl19+qSiKoiQnJxfOapqYmKgkJycriqIonTp1UsaMGVOk1saNGyuTJ0++7fEFBQUpTk5OyrRp05SYmBhlxowZilarVTZs2FC4zpdffqls2bJFOXv2rLJ582alTp06yvPPP1/4+oIFCxQrKyulVatWyq5du5STJ08q169fVzZv3qz88MMPSnR0tBIdHa2MGDFC8fb2LjIVPKBUr15dWbJkiRITE6P06dNHCQ4OVh555BFl3bp1SnR0tNKiRQula9euhdusW7dOqVatmrJw4ULlzJkzyoYNG5Tg4GDl3XffvePP527b3ajHy8tLmTdvnnLmzBnl3Llzt/3ZCVFVSUARwgT8O6Ds27dPcXd3VwYMGKBcv35dsbW1LTY1+4gRI5TBgwcrinIzoGzatKnw9TVr1iiAkpOTc9v3rV+/vjJz5szC57cGFEVRP0hXrFhRZJslS5Yorq6uSm5urqIoavDRaDRKXFzcbd8nKCioyIe/oijKwIEDlW7dut12m6VLlxYGNEVRAwqgREVF3XYbRVGUgoICxcnJSfn999+LHMdbb71V+HzPnj0KoMybN69w2c8//6zY2toWPm/btq3y4YcfFtn3Dz/8oPj6+hbZ779/Pve63fjx4+94HEJUdXKJRwgTsXr1ahwdHbG1taVly5a0a9eOmTNnEh0dTW5uLp06dcLR0bHw8f333xe7JNGoUaPC7319fQFITk4GICsri9dee4369evj4uKCo6MjJ0+eJCEhoVR19unTB0tLS1asWAHA/Pnz6dChQ5FLHCVp2bJlsecnTpwofL5161Y6depE9erVcXJyYujQoVy9erVIR2Fra+six3jj+EaPHk3t2rVxdnbG2dmZ69evFzuuW7fz9vYGoGHDhkWW5ebmkpGRAcCBAweYOnVqkZ/5yJEjSUxMJDs7+7bHea/bNW3a9I4/LyGqOukkK4SJ6NChA7Nnz8bKygo/P7/CTpNxcXEArFmzhurVqxfZxsbGpsjzWztaajQaAAwGAwCvvvoq69ev57PPPiM0NBQ7OzueeOIJ8vPzS1WntbU1Q4YMYcGCBTz++OMsWrTovm9NvlFjfHw8jz32GKNHj+a9997Dzc2NP//8kxEjRqDT6QrXt7OzK9zmhmHDhnHlyhWmT59OUFAQNjY2tGzZsthxlfSzudPPy2AwMGXKFB5//PFiddva2t72mO51OwcHh9vuQwghAUUIk+Hg4EBoaGix5Tc6hCYkJNC+ffv73v/OnTsZNmwYffv2BeD69eucO3fujttYWVmh1+uLLX/22Wdp0KABs2bNQqfTlfhh/G979+4t9rxu3boA7N+/n4KCAj7//PPCu3KWLl16L4fFzp07mTVrFo899hgA58+fJyUl5Z62vZPIyEhiYmJKPCc3lPTzuZfthBB3JwFFCBPn5OTEf//7X15++WUMBgNt2rQhIyOD3bt34+joyNNPP31P+wkNDWX58uX07NkTjUbD22+/XdhacDvBwcFs3ryZ1q1bY2Njg6urKwD16tWjRYsWTJw4keHDh2NnZ3fX99+1axeffPIJffr0YePGjSxbtow1a9YAULNmTQoKCpg5cyY9e/Zk165dzJkz556P64cffqBp06ZkZGTw6quv3lM9dzN58mR69OhBQEAA/fv3x8LCgiNHjnD06NHCu25K+vncy3ZCiLuTPihCmIH33nuPyZMnM23aNOrVq0eXLl34/fffCQkJued9fPnll7i6utKqVSt69uxJly5diIyMvOM2n3/+ORs3biQgIIDGjRsXeW3EiBHk5+czfPjwe3r/V155hQMHDtC4cWPee+89Pv/8c7p06QJAREQEX3zxBR9//DENGjTgp59+Ytq0afe03/nz55OWlkbjxo0ZMmQI48aNw8vL6562vZMuXbqwevVqNm7cyEMPPUSLFi344osvCAoKKlynpJ/PvWwnhLg7jaLcZuACIYS4gw8++IDFixdz9OjRu64bHBzM+PHjGT9+fPkXJoSoFKQFRQhRKtevX+fvv/9m5syZjBs3ztjlCCEqKQkoQohSGTt2LG3atKF9+/b3fHlHCCFKSy7xCCGEEMLkSAuKEEIIIUyOBBQhhBBCmBwJKEIIIYQwORJQhBBCCGFyJKAIIYQQwuRIQBFCCCGEyZGAIoQQQgiTIwFFCCGEECbn/wEiMpJXNxmbtQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas_to_try, bias**2, label = \"Bias^2\")\n",
    "plt.plot(alphas_to_try, variance, label = \"Variance\")\n",
    "plt.plot(alphas_to_try, mse, label = \"MSE\")\n",
    "plt.xlabel('Penalty parameter')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991f423-bba9-407e-be69-a00eed9d3a18",
   "metadata": {},
   "source": [
    "#### Can a ridge regression give a better prediction than OLS?\n",
    "Based on the plot, a Ridge regression appears to offer a worse prediction compared to OLS, as indicated by the increasing trend in the MSE values across different values of lambda. This means that adding a penalty term in this dataset doesn't improve the predictive performance compared to the OLS regression. Therrefore, a simpler OLS model might provide better prediction results. However, in other datasets - like in the example in class-, Ridge Regression can have a better predictive performance compared to OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796cdb95-4c8c-44ef-8f29-d008f8df5462",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Linear regression\n",
    " Suppose we estimate the regression coefficients in a linear regression\n",
    "model by minimizing the function provided for a particular value of s. For parts (a) through (e), indicate which\n",
    "of i. through v. is correct. Justify your answer.\n",
    "\n",
    "- (a) As we increase s from 0, the training RSS will:\n",
    "    - i. Increase initially, and then eventually start decreasing in an inverted U shape.\n",
    "    - ii. Decrease initially, and then eventually start increasing in a U shape.\n",
    "    - iii. Steadily increase.\n",
    "    - iv. Steadily decrease.\n",
    "    - v. Remain constant.\n",
    "- (b) Repeat (a) for test RSS.\n",
    "- (c) Repeat (a) for variance.\n",
    "- (d) Repeat (a) for (squared) bias.\n",
    "- (e) Repeat (a) for the irreducible error.\n",
    "\n",
    "---\n",
    "\n",
    "Objective:\n",
    "\n",
    "The exercise aims to understand how the training residual sum of squares (RSS), test RSS, variance, squared bias, and irreducible error change as we vary the regularization parameter s in a linear regression model.\n",
    "Linear Regression with Regularization:\n",
    "\n",
    "In a linear regression model, we aim to minimize the difference between observed and predicted values of the response variable (RSS). However, in this exercise, we impose a constraint on the magnitude of the regression coefficients (β) such that the sum of absolute values of coefficients does not exceed a certain threshold s.\n",
    "Effect of Increasing s:\n",
    "\n",
    "As s increases from 0, the constraint becomes less restrictive, allowing larger coefficient values.\n",
    "\n",
    "Let's analyze the expected behavior for each of the metrics:\n",
    "\n",
    "(a) Training RSS: Initially, with a small s, the model is heavily regularized, leading to underfitting and higher training RSS. As s increases, the model becomes less regularized, fitting the training data better, and thus training RSS decreases. However, if s becomes too large, overfitting may occur, causing the training RSS to increase again.\n",
    "\n",
    "(b) Test RSS: The test RSS typically follows a similar pattern to the training RSS. Initially, with a small s, the model generalizes poorly to unseen data, leading to high test RSS. As s increases, the model becomes better at generalizing, resulting in lower test RSS. However, if s becomes too large, overfitting may occur, causing test RSS to increase again.\n",
    "\n",
    "(c) Variance: Variance tends to decrease as s increases because the model becomes less complex and more stable.\n",
    "\n",
    "(d) Squared Bias: Bias tends to decrease initially as s increases because the model becomes more flexible and can capture more complex relationships in the data. However, if s becomes too large, bias may increase due to overfitting.\n",
    "\n",
    "(e) Irreducible Error: Irreducible error remains constant regardless of the value of s because it represents the inherent noise in the data that cannot be reduced by any model.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "In summary, as we increase s from 0:\n",
    "Training RSS and test RSS are expected to initially increase and then decrease or remain relatively stable, depending on the balance between model flexibility and overfitting.\n",
    "Variance is expected to decrease.\n",
    "Bias is expected to decrease initially and then may increase if overfitting occurs.\n",
    "Irreducible error remains constant.\n",
    "This exercise helps in understanding the trade-offs involved in choosing the appropriate level of regularization in a linear regression model and its impact on various aspects of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776fd57-3df3-43fa-8ed0-5ca9dbddd4a1",
   "metadata": {},
   "source": [
    "## 3. Principal Component Analysis (PCA):\n",
    "\n",
    "- We then move on to the second exercise, which involves a dense regression model with 50 correlated predictors. Using PCA, we compute the principal components of the predictors and their corresponding scores.\n",
    "- We estimate OLS regression models using both the original predictors and the principal components on a training sample. Then, we use these models to predict the outcomes in a test sample and compute the mean squared prediction error (MSPE) for comparison.\n",
    "- Finally, we discuss and explain the patterns observed in the MSPE for different sample sizes in comparison with a reference table provided in lecture slides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a62a8-484c-4dc1-8b3b-ea18e30df553",
   "metadata": {},
   "source": [
    "#### 3. Consider the ’dense’ regression model discussed in the last lecture: Yi = β0 + β1X1i + β2X2i + . . . + β50X50,i + ϵi, where X1, . . . , X50 are correlated jointly normal random variables, ϵ ∼ N(0, 22), and the regression coefficients are arbitrarily chosen numbers between 0 and 1 (not shown). The file PCA data.csv contains a training sample of size n = 500 and a test sample of size m = 500 generated from this model. The exercise below asks you to do the exercise that produces the last column of the ’Dense DGP’ table on slide 22, Lecture 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d63c6b-af29-4b44-b34a-ac9075a1d697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.539179</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>1.259177</td>\n",
       "      <td>0.763472</td>\n",
       "      <td>0.128735</td>\n",
       "      <td>0.410222</td>\n",
       "      <td>0.420989</td>\n",
       "      <td>-0.101123</td>\n",
       "      <td>-1.242581</td>\n",
       "      <td>0.029933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859282</td>\n",
       "      <td>-1.645036</td>\n",
       "      <td>-0.247500</td>\n",
       "      <td>1.372374</td>\n",
       "      <td>-0.212618</td>\n",
       "      <td>-1.368046</td>\n",
       "      <td>-1.740719</td>\n",
       "      <td>0.925212</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>-1.020763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.036508</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>-1.951131</td>\n",
       "      <td>-1.097787</td>\n",
       "      <td>0.919061</td>\n",
       "      <td>-0.069719</td>\n",
       "      <td>0.405042</td>\n",
       "      <td>1.808955</td>\n",
       "      <td>-0.343013</td>\n",
       "      <td>1.465924</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.809128</td>\n",
       "      <td>0.381091</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>0.632532</td>\n",
       "      <td>-1.429868</td>\n",
       "      <td>-2.092106</td>\n",
       "      <td>0.499216</td>\n",
       "      <td>1.026407</td>\n",
       "      <td>-0.763639</td>\n",
       "      <td>-0.405548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.295433</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>1.127620</td>\n",
       "      <td>1.458154</td>\n",
       "      <td>0.227844</td>\n",
       "      <td>-2.003859</td>\n",
       "      <td>-1.775359</td>\n",
       "      <td>-2.480777</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>0.852822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091664</td>\n",
       "      <td>0.655664</td>\n",
       "      <td>-0.191965</td>\n",
       "      <td>1.194055</td>\n",
       "      <td>0.326962</td>\n",
       "      <td>0.399151</td>\n",
       "      <td>0.723069</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>-1.132469</td>\n",
       "      <td>0.212292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.825405</td>\n",
       "      <td>0.845641</td>\n",
       "      <td>-0.921489</td>\n",
       "      <td>-1.368601</td>\n",
       "      <td>2.085195</td>\n",
       "      <td>-0.294420</td>\n",
       "      <td>1.029018</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>-0.677591</td>\n",
       "      <td>-1.276767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280935</td>\n",
       "      <td>-0.523440</td>\n",
       "      <td>-0.230028</td>\n",
       "      <td>1.939640</td>\n",
       "      <td>-0.429125</td>\n",
       "      <td>0.701319</td>\n",
       "      <td>-1.008541</td>\n",
       "      <td>1.055334</td>\n",
       "      <td>-0.782659</td>\n",
       "      <td>0.749695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.176432</td>\n",
       "      <td>0.566670</td>\n",
       "      <td>0.667277</td>\n",
       "      <td>-0.248455</td>\n",
       "      <td>1.361258</td>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.149155</td>\n",
       "      <td>-0.271543</td>\n",
       "      <td>0.229179</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728898</td>\n",
       "      <td>-0.124473</td>\n",
       "      <td>-0.842829</td>\n",
       "      <td>-0.132558</td>\n",
       "      <td>-0.236122</td>\n",
       "      <td>-0.751535</td>\n",
       "      <td>0.191009</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>-0.350858</td>\n",
       "      <td>0.384321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-3.298207</td>\n",
       "      <td>1.152532</td>\n",
       "      <td>0.610173</td>\n",
       "      <td>2.956214</td>\n",
       "      <td>-1.432405</td>\n",
       "      <td>-2.397398</td>\n",
       "      <td>-0.945650</td>\n",
       "      <td>-0.952754</td>\n",
       "      <td>-0.825043</td>\n",
       "      <td>0.508768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263616</td>\n",
       "      <td>1.249821</td>\n",
       "      <td>0.778397</td>\n",
       "      <td>-0.360644</td>\n",
       "      <td>1.407061</td>\n",
       "      <td>1.214776</td>\n",
       "      <td>0.113185</td>\n",
       "      <td>-1.092583</td>\n",
       "      <td>-0.705830</td>\n",
       "      <td>-0.492108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.334896</td>\n",
       "      <td>-0.434171</td>\n",
       "      <td>-0.293504</td>\n",
       "      <td>-1.437907</td>\n",
       "      <td>-0.106369</td>\n",
       "      <td>1.617408</td>\n",
       "      <td>1.136066</td>\n",
       "      <td>0.214231</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>-2.389823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334054</td>\n",
       "      <td>0.202016</td>\n",
       "      <td>-0.348515</td>\n",
       "      <td>1.547892</td>\n",
       "      <td>-0.924954</td>\n",
       "      <td>-0.393573</td>\n",
       "      <td>0.810303</td>\n",
       "      <td>-0.265939</td>\n",
       "      <td>0.290818</td>\n",
       "      <td>0.370616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.049071</td>\n",
       "      <td>-1.474982</td>\n",
       "      <td>-0.437761</td>\n",
       "      <td>-0.264495</td>\n",
       "      <td>-1.270952</td>\n",
       "      <td>0.129644</td>\n",
       "      <td>-0.668138</td>\n",
       "      <td>-0.298138</td>\n",
       "      <td>1.466069</td>\n",
       "      <td>-1.368111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424773</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>-0.098820</td>\n",
       "      <td>-0.281987</td>\n",
       "      <td>0.727978</td>\n",
       "      <td>0.530025</td>\n",
       "      <td>0.860666</td>\n",
       "      <td>1.001294</td>\n",
       "      <td>0.159725</td>\n",
       "      <td>0.409749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-6.145876</td>\n",
       "      <td>0.349684</td>\n",
       "      <td>-0.670108</td>\n",
       "      <td>0.161680</td>\n",
       "      <td>-0.250096</td>\n",
       "      <td>-0.658828</td>\n",
       "      <td>-0.076775</td>\n",
       "      <td>-0.338317</td>\n",
       "      <td>-1.390537</td>\n",
       "      <td>-0.565669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377252</td>\n",
       "      <td>-0.221610</td>\n",
       "      <td>0.200315</td>\n",
       "      <td>0.616052</td>\n",
       "      <td>1.238358</td>\n",
       "      <td>0.175405</td>\n",
       "      <td>1.963846</td>\n",
       "      <td>-1.160791</td>\n",
       "      <td>-0.170900</td>\n",
       "      <td>-0.414812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.320450</td>\n",
       "      <td>1.429819</td>\n",
       "      <td>1.601074</td>\n",
       "      <td>0.964628</td>\n",
       "      <td>0.272910</td>\n",
       "      <td>0.848267</td>\n",
       "      <td>1.272262</td>\n",
       "      <td>1.013718</td>\n",
       "      <td>-1.256276</td>\n",
       "      <td>-0.398812</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.903293</td>\n",
       "      <td>1.517092</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>-1.859139</td>\n",
       "      <td>-0.232359</td>\n",
       "      <td>0.162459</td>\n",
       "      <td>-0.193444</td>\n",
       "      <td>-1.936912</td>\n",
       "      <td>0.381345</td>\n",
       "      <td>0.132111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y        X1        X2        X3        X4        X5        X6  \\\n",
       "0   -6.539179  0.948014  1.259177  0.763472  0.128735  0.410222  0.420989   \n",
       "1    2.036508  0.019661 -1.951131 -1.097787  0.919061 -0.069719  0.405042   \n",
       "2    7.295433  0.283019  1.127620  1.458154  0.227844 -2.003859 -1.775359   \n",
       "3    6.825405  0.845641 -0.921489 -1.368601  2.085195 -0.294420  1.029018   \n",
       "4   -0.176432  0.566670  0.667277 -0.248455  1.361258  0.041326  0.149155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -3.298207  1.152532  0.610173  2.956214 -1.432405 -2.397398 -0.945650   \n",
       "996  2.334896 -0.434171 -0.293504 -1.437907 -0.106369  1.617408  1.136066   \n",
       "997 -1.049071 -1.474982 -0.437761 -0.264495 -1.270952  0.129644 -0.668138   \n",
       "998 -6.145876  0.349684 -0.670108  0.161680 -0.250096 -0.658828 -0.076775   \n",
       "999 -1.320450  1.429819  1.601074  0.964628  0.272910  0.848267  1.272262   \n",
       "\n",
       "           X7        X8        X9  ...       X41       X42       X43  \\\n",
       "0   -0.101123 -1.242581  0.029933  ... -0.859282 -1.645036 -0.247500   \n",
       "1    1.808955 -0.343013  1.465924  ... -1.809128  0.381091  0.497534   \n",
       "2   -2.480777  0.506680  0.852822  ...  0.091664  0.655664 -0.191965   \n",
       "3    0.098418 -0.677591 -1.276767  ... -0.280935 -0.523440 -0.230028   \n",
       "4   -0.271543  0.229179  0.089760  ... -0.728898 -0.124473 -0.842829   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995 -0.952754 -0.825043  0.508768  ...  1.263616  1.249821  0.778397   \n",
       "996  0.214231  0.032185 -2.389823  ... -0.334054  0.202016 -0.348515   \n",
       "997 -0.298138  1.466069 -1.368111  ...  0.424773  0.706320 -0.098820   \n",
       "998 -0.338317 -1.390537 -0.565669  ...  1.377252 -0.221610  0.200315   \n",
       "999  1.013718 -1.256276 -0.398812  ... -2.903293  1.517092  0.065016   \n",
       "\n",
       "          X44       X45       X46       X47       X48       X49       X50  \n",
       "0    1.372374 -0.212618 -1.368046 -1.740719  0.925212  0.123907 -1.020763  \n",
       "1    0.632532 -1.429868 -2.092106  0.499216  1.026407 -0.763639 -0.405548  \n",
       "2    1.194055  0.326962  0.399151  0.723069  0.939017 -1.132469  0.212292  \n",
       "3    1.939640 -0.429125  0.701319 -1.008541  1.055334 -0.782659  0.749695  \n",
       "4   -0.132558 -0.236122 -0.751535  0.191009  0.007180 -0.350858  0.384321  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.360644  1.407061  1.214776  0.113185 -1.092583 -0.705830 -0.492108  \n",
       "996  1.547892 -0.924954 -0.393573  0.810303 -0.265939  0.290818  0.370616  \n",
       "997 -0.281987  0.727978  0.530025  0.860666  1.001294  0.159725  0.409749  \n",
       "998  0.616052  1.238358  0.175405  1.963846 -1.160791 -0.170900 -0.414812  \n",
       "999 -1.859139 -0.232359  0.162459 -0.193444 -1.936912  0.381345  0.132111  \n",
       "\n",
       "[1000 rows x 51 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data set\n",
    "data = pd.read_csv('PCA_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a4542fa-ef84-4fa1-9d7d-5ac28c954eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data and designating the training and the test sample\n",
    "train_sample = data[:500]\n",
    "test_sample = data[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6cafa-0d33-4f97-b27e-0bcf6075f0fc",
   "metadata": {},
   "source": [
    "#### b) Compute the first 10 principal component vectors and the corresponding scores Z∗1 , . . . , Z∗ 10 for (X1, X2, . . . , X50). For simplicity, you can use the whole data set for this (both the training sample as well as the test sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "748a9383-03f1-4b6b-93b7-5ea46a501ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying PCA and calculating the principal components as X_pca\n",
    "pca = PCA()\n",
    "\n",
    "# Calculating all the principal component scores\n",
    "X_pca = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "522a3674-e5df-41b9-81ec-2fec75c91466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing the first 10 principal component vectors\n",
    "pca_vectors = pca.components_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f569c0-3054-44e5-9371-73d64f754426",
   "metadata": {},
   "source": [
    "#### c) Estimate an OLS regression of Y on a constant and X1, . . . , X50 over the training sample. Estimate OLS regressions of Y on a constant and Z∗1, . . . , Z∗k over the training sample for k = 1, 5, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e068c6b-089a-4ffd-b154-cc338ac76e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming that Y is the target variable, we are dropping it\n",
    "X_train = train_sample.drop('Y', axis = 1)\n",
    "X_test = test_sample.drop('Y', axis = 1)\n",
    "# Setting Y as a new variable\n",
    "y_train = train_sample['Y']\n",
    "y_test = test_sample['Y']\n",
    "\n",
    "# We are fitting it on the original dataset\n",
    "ols_on_X = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b286cb96-f0e0-4678-8879-b636f465086f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS regression without applying PCA:\n",
      "The Intercept is 0.9368192754190612.\n",
      "The MSPE is 23.528930608001616.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 1.\n",
      "The coefficients are: [0.01687943].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 1 value is 15.026864642641463.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 5.\n",
      "The coefficients are: [ 0.01687943  0.04055752 -0.40126178 -0.04866477 -0.9367122 ].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 5 value is 17.429419813414164.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 10.\n",
      "The coefficients are: [ 0.01687943  0.04055752 -0.40126178 -0.04866477 -0.9367122   0.52798791\n",
      " -0.53136266 -0.08113065 -0.6672775  -0.62775569].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 10 value is 20.441690618275057.\n",
      "--------------------------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Iniating empty lists for the results\n",
    "results = []\n",
    "\n",
    "# Predicting for the regression without the PCA and calculating the MSPE\n",
    "prediction_ols = ols_on_X.predict(X_train)\n",
    "mspe_ols = np.mean((prediction_ols - y_test)**2)\n",
    "\n",
    "# Appending it to the results table\n",
    "results.append({'Model': f\"OLS\", \"MSPE\" : mspe_ols})\n",
    "\n",
    "# Printing the results\n",
    "# Taking out the coefficients, because it has 50\n",
    "print('OLS regression without applying PCA:')\n",
    "print(f'The Intercept is {ols_on_X.intercept_}.')\n",
    "print(f'The MSPE is {mspe_ols}.')\n",
    "print('-'*50)\n",
    "print(' ')\n",
    "\n",
    "# Defining a list for the k values\n",
    "k_to_try = [1, 5, 10]\n",
    "\n",
    "# Calculating all the principal component scores\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Defining a for loop for the k values\n",
    "for k in k_to_try:\n",
    "    \n",
    "    # Extracting the first k components\n",
    "    X_train_pca_k = X_train_pca[:, :k]\n",
    "    # Fitting the model\n",
    "    ols_on_pca = LinearRegression().fit(X_train_pca_k, y_train)\n",
    "    \n",
    "    # Calculating the MSPE\n",
    "    prediction_pca = ols_on_pca.predict(X_train_pca_k)\n",
    "    mspe_pca = np.mean((prediction_pca - y_test)**2)\n",
    "    \n",
    "    # Appending the results to the list\n",
    "    results.append({'Model': f\"PCA (k = {k})\", \"MSPE\" : mspe_pca})\n",
    "    \n",
    "    # Printing the results\n",
    "    print(f'k = {k}.')\n",
    "    print(f'The coefficients are: {ols_on_pca.coef_}.')\n",
    "    print(f'The Intercept is {ols_on_pca.intercept_}.')\n",
    "    print(f'The MSPE for k = {k} value is {mspe_pca}.')\n",
    "    print('-'*50)\n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8ae4a-6df5-4fe5-9c6a-0cff778abbaf",
   "metadata": {},
   "source": [
    "#### d) Use the four models estimated under part c) the obtain predictions for the outcomes Yi in the test sample. Compute the mean squared prediction error for the four different predictions and report these numbers. You should get results similar to those on slide 22, but there will be some differences because the whole experiment is performed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ce83a34-43f1-4903-9a03-41390555e956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>23.528931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA (k = 1)</td>\n",
       "      <td>15.026865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA (k = 5)</td>\n",
       "      <td>17.429420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA (k = 10)</td>\n",
       "      <td>20.441691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model       MSPE\n",
       "0           OLS  23.528931\n",
       "1   PCA (k = 1)  15.026865\n",
       "2   PCA (k = 5)  17.429420\n",
       "3  PCA (k = 10)  20.441691"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting all the MSPE values and putting them into a DataFrame\n",
    "mspe_values = pd.DataFrame(results)\n",
    "mspe_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55394ea7-ba9a-4c85-bf4f-60602db1b79f",
   "metadata": {},
   "source": [
    "#### e) Consider again the original ’Dense DGP’ table on slide 22, Lecture 3. Discuss and explain the MSPE patterns you see in the first column (Ntr = 75) and the last column (Ntr = 500)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ccf1a-a98f-49e3-9bc7-418866c53892",
   "metadata": {},
   "source": [
    "\\begin{array}{cccccc}\n",
    "& \\text{Ntr = 75} & \\text{Ntr = 150} & \\text{Ntr = 500} \\\\\n",
    "\\hline\n",
    "\\text{DENSE DGP} & \\text{MSPE} & \\text{MSPE} & \\text{MSPE} \\\\\n",
    "\\text{OLS} & 12.9 & 6.0 & 4.5 \\\\\n",
    "\\text{PCA (k=1)} & 14.9 & 14.7 & 14.6 \\\\\n",
    "\\text{PCA (k=5)} & 13.6 & 13.0 & 12.7 \\\\\n",
    "\\text{PCA (k=10)} & 9.3 & 8.5 & 8.0 \\\\\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac6cf6-922d-457a-aaa9-729760f652e8",
   "metadata": {},
   "source": [
    "- Since we are considering the dense Data Generating Process, all the betas are non-zero.\n",
    "##### N = 75:\n",
    "- When our n = 75, we can see that by taking more PCA (k$1$ = 1, k$2$ = 5, k$3$ = 10), we decrease our MPSE, because we \n",
    "- The OLS model in this case is an overfit.\n",
    "- k = 10 is enough to predict Y better than OLS\n",
    "##### N = 500:\n",
    "- When our n = 500, the OLS's MPSE is lower than the models with PCA, because we compress the information too much. Hence, we are losing information.\n",
    "- If we have a large sample and if we are starting to use PCA, we are beginning to compress our data, which leads to losing information.\n",
    "- Big Data and ML methods are useful when the x predictor number is considerably large compared to the sample size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e0a1b-c290-4580-acf8-555cdbed0217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
