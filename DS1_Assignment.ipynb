{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a294ca1f-c0f5-44c8-b6c5-db4ee4b59090",
   "metadata": {},
   "source": [
    "# <center> Ridge Regression, Linear Regression and PCA<center>\n",
    "\n",
    "<center> Data Science 1 - Final Assignment <center>\n",
    "<center>Created by Zsófia Rebeka Katona<center>\n",
    "\n",
    "    ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098216e-d606-43a8-bbba-552ab40a3245",
   "metadata": {},
   "source": [
    "The goal of this assignment is to explore the concepts of ridge regression, principal component analysis (PCA) in the context of predictive modeling. Moreover, we will discover how the parameters of a linear regression change in a given scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898052d9-729c-4180-be4a-946c56f10173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978c1df-4211-455b-adb9-0879ea8aeb3c",
   "metadata": {},
   "source": [
    "## 1. Ridge Regression Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4551be9-3098-4d53-9189-06a5d4dbc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OLS Estimator is 2.0127181593375885\n",
      "The Ridge Estimator is 1.9168744374643698, when lambda is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Setting the random seed\n",
    "np.random.seed(20240315)\n",
    "\n",
    "# Settings\n",
    "n = 20\n",
    "sigma = 1.0\n",
    "beta_zero = 2\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma, size = n)\n",
    "Y = beta_zero + epsilon\n",
    "\n",
    "# Creating the estimator for the OLS model\n",
    "beta_ols = np.mean(Y)\n",
    "\n",
    "# Defining the Ridge Estimator function\n",
    "def ridge_estimator(n, alpha):\n",
    "    n = len(Y)\n",
    "    return np.sum(Y)/(n + alpha)\n",
    "\n",
    "# Defining a nonzero lambda\n",
    "alpha_ridge = 1.0\n",
    "\n",
    "# Calculating the Ridge Estimator\n",
    "beta_ridge = ridge_estimator(n, alpha_ridge)\n",
    "\n",
    "# Comparing the two values\n",
    "print(f\"The OLS Estimator is {beta_ols}\")\n",
    "print(f\"The Ridge Estimator is {beta_ridge}, when lambda is {alpha_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1c770-a105-4f6f-bbc6-46b3bd7e2541",
   "metadata": {},
   "source": [
    "#### a, How does the regularized estimator (predictor) βˆridge compare with the OLS estimator?\n",
    "- The Ridge Estimator is expected to be smaller as we apply a penalty term and the coefficient will be be smaller. \n",
    "- The penalty term shrinks the coefficients close to 0. Introducing a penalty term results in a shinkrage effect on the coefficient estimates.\n",
    "- The higher the penalty term, the more the coefficients shrink towards 0.\n",
    "\n",
    "#### b, Suppose that β0 = 1 and ϵ ∼ N(0, σ2) with σ2 = 4. Generate a sample of size n = 20 from the model and compute the predicted value Yˆ = ˆf(x) = βˆridge 0 for a grid of λ values over the interval [0, 20]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2405fed6-0534-4d2b-92e2-743f51cda28f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphas</th>\n",
       "      <th>Estimated values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.387243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.330404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.276209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.224477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.175044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.127760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2.082489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.039103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.997489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.957539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.919156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.882249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1.846735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.812536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.779581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.747803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>1.717140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.687534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.5</td>\n",
       "      <td>1.658932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.631283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1.604540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.578661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.5</td>\n",
       "      <td>1.553603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.529328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.5</td>\n",
       "      <td>1.505799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.482984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.5</td>\n",
       "      <td>1.460850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.439367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.5</td>\n",
       "      <td>1.418507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.398242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.5</td>\n",
       "      <td>1.378549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.359402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.5</td>\n",
       "      <td>1.340780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.322662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17.5</td>\n",
       "      <td>1.305026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.5</td>\n",
       "      <td>1.271129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.254833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.5</td>\n",
       "      <td>1.238949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alphas  Estimated values\n",
       "0      0.5          2.387243\n",
       "1      1.0          2.330404\n",
       "2      1.5          2.276209\n",
       "3      2.0          2.224477\n",
       "4      2.5          2.175044\n",
       "5      3.0          2.127760\n",
       "6      3.5          2.082489\n",
       "7      4.0          2.039103\n",
       "8      4.5          1.997489\n",
       "9      5.0          1.957539\n",
       "10     5.5          1.919156\n",
       "11     6.0          1.882249\n",
       "12     6.5          1.846735\n",
       "13     7.0          1.812536\n",
       "14     7.5          1.779581\n",
       "15     8.0          1.747803\n",
       "16     8.5          1.717140\n",
       "17     9.0          1.687534\n",
       "18     9.5          1.658932\n",
       "19    10.0          1.631283\n",
       "20    10.5          1.604540\n",
       "21    11.0          1.578661\n",
       "22    11.5          1.553603\n",
       "23    12.0          1.529328\n",
       "24    12.5          1.505799\n",
       "25    13.0          1.482984\n",
       "26    13.5          1.460850\n",
       "27    14.0          1.439367\n",
       "28    14.5          1.418507\n",
       "29    15.0          1.398242\n",
       "30    15.5          1.378549\n",
       "31    16.0          1.359402\n",
       "32    16.5          1.340780\n",
       "33    17.0          1.322662\n",
       "34    17.5          1.305026\n",
       "35    18.0          1.287855\n",
       "36    18.5          1.271129\n",
       "37    19.0          1.254833\n",
       "38    19.5          1.238949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings for exercise b\n",
    "sigma = 2\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma**2, size = n)\n",
    "\n",
    "Y = beta_ridge + epsilon\n",
    "\n",
    "# Setting the lambda from 0 to 20 with increments of 0.5\n",
    "alphas_to_try = np.arange(0.5, 20, 0.5)\n",
    "\n",
    "# Creating an empty array\n",
    "results = []\n",
    "\n",
    "# Defining a for loop to calculate the estimated values\n",
    "for alpha in alphas_to_try:\n",
    "    beta_ridge = ridge_estimator(n, alpha)\n",
    "    results.append(beta_ridge)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "alpha_results = pd.DataFrame({\n",
    "    \"Alphas\" : alphas_to_try,\n",
    "    \"Estimated values\" : results\n",
    "})\n",
    "\n",
    "alpha_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b677b7-25d8-412b-847b-2552d3ca3bab",
   "metadata": {},
   "source": [
    "#### c,  Repeat part b), say, 1000 times so that you end up with 1000 estimates of β0 for all the λ values that you have picked. For each value of λ, compute bias2 [βˆridge0], Var[βˆridge0] and MSE[βˆridge0] = bias2[βˆridge0] + Var[βˆridge0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333bf18d-93f6-471a-b766-c4d0a1429778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.06102299, -0.10718911, -0.15120797, -0.19322597, -0.23337651,\n",
       "        -0.27178136, -0.30855197, -0.34379047, -0.37759067, -0.41003886,\n",
       "        -0.44121456, -0.47119121, -0.50003666, -0.52781375, -0.55458078,\n",
       "        -0.58039183, -0.60529724, -0.62934384, -0.6525753 , -0.67503238,\n",
       "        -0.69675316, -0.71777327, -0.73812608, -0.75784286, -0.77695297,\n",
       "        -0.79548398, -0.81346183, -0.83091092, -0.84785424, -0.86431347,\n",
       "        -0.88030905, -0.89586032, -0.91098552, -0.92570193, -0.9400259 ,\n",
       "        -0.95397293, -0.9675577 , -0.98079414, -0.99369548]),\n",
       " array([0.19222555, 0.18318092, 0.17475995, 0.16690659, 0.15957094,\n",
       "        0.15270848, 0.14627938, 0.14024789, 0.1345819 , 0.12925246,\n",
       "        0.12423343, 0.11950116, 0.11503423, 0.11081315, 0.10682021,\n",
       "        0.10303927, 0.09945557, 0.09605563, 0.0928271 , 0.08975865,\n",
       "        0.08683987, 0.08406117, 0.08141374, 0.07888944, 0.07648075,\n",
       "        0.0741807 , 0.07198288, 0.0698813 , 0.06787044, 0.06594513,\n",
       "        0.0641006 , 0.0623324 , 0.06063636, 0.05900861, 0.05744554,\n",
       "        0.05594376, 0.05450011, 0.05311163, 0.05177554]),\n",
       " array([0.19594936, 0.19467043, 0.1976238 , 0.20424286, 0.21403553,\n",
       "        0.22657359, 0.2414837 , 0.25843978, 0.27715662, 0.29738432,\n",
       "        0.31890372, 0.34152232, 0.36507089, 0.38940051, 0.41438005,\n",
       "        0.43989395, 0.46584032, 0.4921293 , 0.51868163, 0.54542737,\n",
       "        0.57230483, 0.59925964, 0.62624385, 0.65321523, 0.68013666,\n",
       "        0.70697547, 0.73370303, 0.76029427, 0.78672725, 0.8129829 ,\n",
       "        0.83904463, 0.8648981 , 0.89053097, 0.91593267, 0.94109424,\n",
       "        0.96600811, 0.99066801, 1.01506877, 1.03920624]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = 1000\n",
    "epsilon = np.random.normal(loc = 0, scale = sigma**2, size = (R, n))\n",
    "\n",
    "# Creating empty arrays to store the results\n",
    "estimated_results = np.empty((R, len(alphas_to_try)))\n",
    "bias_sq = np.empty(len(alphas_to_try))\n",
    "var = np.empty(len(alphas_to_try))\n",
    "mse = np.empty(len(alphas_to_try))\n",
    "\n",
    "# Creating a for loop for the 1000 estimates\n",
    "# 'i' stands for the number of iterations and 'j' represents the lambas' index\n",
    "for i in range(R):\n",
    "    epsilon = np.random.normal(0, sigma, size = n)\n",
    "    Y = beta_zero + epsilon\n",
    "    for j, alpha in enumerate(alphas_to_try):\n",
    "        beta_ridge = ridge_estimator(n, alpha)\n",
    "        estimated_results[i, j] = beta_ridge\n",
    "results\n",
    "    \n",
    "# Calculating the bias squared, variance and mse results\n",
    "bias = np.mean(estimated_results - beta_zero, axis = 0)\n",
    "\n",
    "# Calculating the mean of estimated_results\n",
    "estimated_mean = np.mean(estimated_results, axis=0)\n",
    "\n",
    "# Calculating the variance using the formula\n",
    "variance = np.mean((estimated_results - estimated_mean) ** 2, axis=0)\n",
    "\n",
    "# Calculating the mse\n",
    "mse = np.mean(((estimated_results - beta_zero)**2), axis = 0)\n",
    "bias, variance, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31597d8-2114-48a7-b0f9-affb53c3e90b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas_to_try, bias**2, label = \"Bias^2\")\n",
    "plt.plot(alphas_to_try, variance, label = \"Variance\")\n",
    "plt.plot(alphas_to_try, mse, label = \"MSE\")\n",
    "plt.xlabel('Penalty parameter')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991f423-bba9-407e-be69-a00eed9d3a18",
   "metadata": {},
   "source": [
    "#### Can a ridge regression give a better prediction than OLS?\n",
    "Based on the plot, a Ridge regression appears to offer a worse prediction compared to OLS, as indicated by the increasing trend in the MSE values across different values of lambda. This means that adding a penalty term in this dataset doesn't improve the predictive performance compared to the OLS regression. Therefore, a simpler OLS model might provide better prediction results. However, in other datasets - like in the example in class-, Ridge Regression can have a better predictive performance compared to OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208ce51-3c93-4203-aaf8-cd8e003e8fdd",
   "metadata": {},
   "source": [
    "## 2. Linear regression\n",
    "---\n",
    " Suppose we estimate the regression coefficients in a linear regression\n",
    "model by minimizing\n",
    "\n",
    "$$\\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2$$\n",
    "subject to $$\\sum_{j=1}^{p} |\\beta_j| \\leq s$$\n",
    "\n",
    "the function provided for a particular value of *s*. For parts (a) through (e), indicate which\n",
    "of \\( i. \\) through \\( v. \\) is correct. Justify your answer.\n",
    "\n",
    "- (a) As we increase *s* from 0, the training RSS will:\n",
    "    - \\( i. \\) Increase initially, and then eventually start decreasing in an inverted U shape.\n",
    "    - \\( ii. \\) Decrease initially, and then eventually start increasing in a U shape.\n",
    "    - \\( iii. \\) Steadily increase.\n",
    "    - \\( iv. \\) Steadily decrease.\n",
    "    - \\( v. \\) Remain constant.\n",
    "- (b) Repeat (a) for test RSS.\n",
    "- (c) Repeat (a) for variance.\n",
    "- (d) Repeat (a) for (squared) bias.\n",
    "- (e) Repeat (a) for the irreducible error.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796cdb95-4c8c-44ef-8f29-d008f8df5462",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Answer:\n",
    "We want to understand how the training residual sum of squares (RSS), test RSS, variance, squared bias and irreducibel error change as we change the regularization parameter in a linear regression model. *s* in this case refers to the complexity of our f function.\n",
    "\n",
    "(a) Training RSS: Initially, our model has a high training RSS and regularized heavily, suggesting that it's an underfit. As s increases, the model becomes less regularized, and RSS decreases. This implies that the model fits on the training data better. However, if we increase s further, our model might become an ovefit, resulting in an increase of training RSS. In this case, scenario ( ii. ) will occur: The training RSS decreases initially, and then eventually start increasing in a u shape.\n",
    "\n",
    "(b) Test RSS: Test RSS performs similar to the training RSS. With a small complexity, our model underpredicts and obtains a higher test RSS. As s increases, the model becomes better at capturing patterns and regularizing, and RSS decreases. However, only until a certain point, because as s becomes too large, our model will be an overfit, and the RSS will increase again. Case ( ii. )\n",
    "\n",
    "(c) Variance: As our s increases, the variance in our model steadily increases. As the complexity of our model increases, it captures more variance and more complex relationship between predictor variables and target variable. In this case, we can opt for ( iii. )\n",
    "\n",
    "(d) (Squared) bias: As s increases, our model becomes more complex. This increased flexibility decreases the bias in our model. While s is low, our model is expected to be an underfit with large bias. But the more pattern our model captures, the less bias will it obtain. In the case bias, ( iv. ) is true. This model represents the trade-off well between bias and variance. However, the squared bias in this model expected decrease initially and then stabilize or potentially increase. Squares bias follows the pattern in ( ii. ).\n",
    "\n",
    "(e) Irreducible error: The irreducible error remains constant regardless of the value of s or any other parameter. It represents the inherent variability in the target variable that cannot be reduced by any model, no matter how well-fitted or complex it is. This error is usually caused by factors that are outside of the scope of our model, for instance, random noise. Hence, we opt for ( v. ) in the case of irreducible errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776fd57-3df3-43fa-8ed0-5ca9dbddd4a1",
   "metadata": {},
   "source": [
    "## 3. Principal Component Analysis (PCA):\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a62a8-484c-4dc1-8b3b-ea18e30df553",
   "metadata": {},
   "source": [
    "#### 3. Consider the ’dense’ regression model discussed in the last lecture: Yi = β0 + β1X1i + β2X2i + . . . + β50X50,i + ϵi, where X1, . . . , X50 are correlated jointly normal random variables, ϵ ∼ N(0, 22), and the regression coefficients are arbitrarily chosen numbers between 0 and 1 (not shown). The file PCA data.csv contains a training sample of size n = 500 and a test sample of size m = 500 generated from this model. The exercise below asks you to do the exercise that produces the last column of the ’Dense DGP’ table on slide 22, Lecture 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d63c6b-af29-4b44-b34a-ac9075a1d697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.539179</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>1.259177</td>\n",
       "      <td>0.763472</td>\n",
       "      <td>0.128735</td>\n",
       "      <td>0.410222</td>\n",
       "      <td>0.420989</td>\n",
       "      <td>-0.101123</td>\n",
       "      <td>-1.242581</td>\n",
       "      <td>0.029933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859282</td>\n",
       "      <td>-1.645036</td>\n",
       "      <td>-0.247500</td>\n",
       "      <td>1.372374</td>\n",
       "      <td>-0.212618</td>\n",
       "      <td>-1.368046</td>\n",
       "      <td>-1.740719</td>\n",
       "      <td>0.925212</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>-1.020763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.036508</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>-1.951131</td>\n",
       "      <td>-1.097787</td>\n",
       "      <td>0.919061</td>\n",
       "      <td>-0.069719</td>\n",
       "      <td>0.405042</td>\n",
       "      <td>1.808955</td>\n",
       "      <td>-0.343013</td>\n",
       "      <td>1.465924</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.809128</td>\n",
       "      <td>0.381091</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>0.632532</td>\n",
       "      <td>-1.429868</td>\n",
       "      <td>-2.092106</td>\n",
       "      <td>0.499216</td>\n",
       "      <td>1.026407</td>\n",
       "      <td>-0.763639</td>\n",
       "      <td>-0.405548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.295433</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>1.127620</td>\n",
       "      <td>1.458154</td>\n",
       "      <td>0.227844</td>\n",
       "      <td>-2.003859</td>\n",
       "      <td>-1.775359</td>\n",
       "      <td>-2.480777</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>0.852822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091664</td>\n",
       "      <td>0.655664</td>\n",
       "      <td>-0.191965</td>\n",
       "      <td>1.194055</td>\n",
       "      <td>0.326962</td>\n",
       "      <td>0.399151</td>\n",
       "      <td>0.723069</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>-1.132469</td>\n",
       "      <td>0.212292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.825405</td>\n",
       "      <td>0.845641</td>\n",
       "      <td>-0.921489</td>\n",
       "      <td>-1.368601</td>\n",
       "      <td>2.085195</td>\n",
       "      <td>-0.294420</td>\n",
       "      <td>1.029018</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>-0.677591</td>\n",
       "      <td>-1.276767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280935</td>\n",
       "      <td>-0.523440</td>\n",
       "      <td>-0.230028</td>\n",
       "      <td>1.939640</td>\n",
       "      <td>-0.429125</td>\n",
       "      <td>0.701319</td>\n",
       "      <td>-1.008541</td>\n",
       "      <td>1.055334</td>\n",
       "      <td>-0.782659</td>\n",
       "      <td>0.749695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.176432</td>\n",
       "      <td>0.566670</td>\n",
       "      <td>0.667277</td>\n",
       "      <td>-0.248455</td>\n",
       "      <td>1.361258</td>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.149155</td>\n",
       "      <td>-0.271543</td>\n",
       "      <td>0.229179</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728898</td>\n",
       "      <td>-0.124473</td>\n",
       "      <td>-0.842829</td>\n",
       "      <td>-0.132558</td>\n",
       "      <td>-0.236122</td>\n",
       "      <td>-0.751535</td>\n",
       "      <td>0.191009</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>-0.350858</td>\n",
       "      <td>0.384321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-3.298207</td>\n",
       "      <td>1.152532</td>\n",
       "      <td>0.610173</td>\n",
       "      <td>2.956214</td>\n",
       "      <td>-1.432405</td>\n",
       "      <td>-2.397398</td>\n",
       "      <td>-0.945650</td>\n",
       "      <td>-0.952754</td>\n",
       "      <td>-0.825043</td>\n",
       "      <td>0.508768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263616</td>\n",
       "      <td>1.249821</td>\n",
       "      <td>0.778397</td>\n",
       "      <td>-0.360644</td>\n",
       "      <td>1.407061</td>\n",
       "      <td>1.214776</td>\n",
       "      <td>0.113185</td>\n",
       "      <td>-1.092583</td>\n",
       "      <td>-0.705830</td>\n",
       "      <td>-0.492108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.334896</td>\n",
       "      <td>-0.434171</td>\n",
       "      <td>-0.293504</td>\n",
       "      <td>-1.437907</td>\n",
       "      <td>-0.106369</td>\n",
       "      <td>1.617408</td>\n",
       "      <td>1.136066</td>\n",
       "      <td>0.214231</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>-2.389823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334054</td>\n",
       "      <td>0.202016</td>\n",
       "      <td>-0.348515</td>\n",
       "      <td>1.547892</td>\n",
       "      <td>-0.924954</td>\n",
       "      <td>-0.393573</td>\n",
       "      <td>0.810303</td>\n",
       "      <td>-0.265939</td>\n",
       "      <td>0.290818</td>\n",
       "      <td>0.370616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.049071</td>\n",
       "      <td>-1.474982</td>\n",
       "      <td>-0.437761</td>\n",
       "      <td>-0.264495</td>\n",
       "      <td>-1.270952</td>\n",
       "      <td>0.129644</td>\n",
       "      <td>-0.668138</td>\n",
       "      <td>-0.298138</td>\n",
       "      <td>1.466069</td>\n",
       "      <td>-1.368111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424773</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>-0.098820</td>\n",
       "      <td>-0.281987</td>\n",
       "      <td>0.727978</td>\n",
       "      <td>0.530025</td>\n",
       "      <td>0.860666</td>\n",
       "      <td>1.001294</td>\n",
       "      <td>0.159725</td>\n",
       "      <td>0.409749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-6.145876</td>\n",
       "      <td>0.349684</td>\n",
       "      <td>-0.670108</td>\n",
       "      <td>0.161680</td>\n",
       "      <td>-0.250096</td>\n",
       "      <td>-0.658828</td>\n",
       "      <td>-0.076775</td>\n",
       "      <td>-0.338317</td>\n",
       "      <td>-1.390537</td>\n",
       "      <td>-0.565669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377252</td>\n",
       "      <td>-0.221610</td>\n",
       "      <td>0.200315</td>\n",
       "      <td>0.616052</td>\n",
       "      <td>1.238358</td>\n",
       "      <td>0.175405</td>\n",
       "      <td>1.963846</td>\n",
       "      <td>-1.160791</td>\n",
       "      <td>-0.170900</td>\n",
       "      <td>-0.414812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.320450</td>\n",
       "      <td>1.429819</td>\n",
       "      <td>1.601074</td>\n",
       "      <td>0.964628</td>\n",
       "      <td>0.272910</td>\n",
       "      <td>0.848267</td>\n",
       "      <td>1.272262</td>\n",
       "      <td>1.013718</td>\n",
       "      <td>-1.256276</td>\n",
       "      <td>-0.398812</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.903293</td>\n",
       "      <td>1.517092</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>-1.859139</td>\n",
       "      <td>-0.232359</td>\n",
       "      <td>0.162459</td>\n",
       "      <td>-0.193444</td>\n",
       "      <td>-1.936912</td>\n",
       "      <td>0.381345</td>\n",
       "      <td>0.132111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y        X1        X2        X3        X4        X5        X6  \\\n",
       "0   -6.539179  0.948014  1.259177  0.763472  0.128735  0.410222  0.420989   \n",
       "1    2.036508  0.019661 -1.951131 -1.097787  0.919061 -0.069719  0.405042   \n",
       "2    7.295433  0.283019  1.127620  1.458154  0.227844 -2.003859 -1.775359   \n",
       "3    6.825405  0.845641 -0.921489 -1.368601  2.085195 -0.294420  1.029018   \n",
       "4   -0.176432  0.566670  0.667277 -0.248455  1.361258  0.041326  0.149155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -3.298207  1.152532  0.610173  2.956214 -1.432405 -2.397398 -0.945650   \n",
       "996  2.334896 -0.434171 -0.293504 -1.437907 -0.106369  1.617408  1.136066   \n",
       "997 -1.049071 -1.474982 -0.437761 -0.264495 -1.270952  0.129644 -0.668138   \n",
       "998 -6.145876  0.349684 -0.670108  0.161680 -0.250096 -0.658828 -0.076775   \n",
       "999 -1.320450  1.429819  1.601074  0.964628  0.272910  0.848267  1.272262   \n",
       "\n",
       "           X7        X8        X9  ...       X41       X42       X43  \\\n",
       "0   -0.101123 -1.242581  0.029933  ... -0.859282 -1.645036 -0.247500   \n",
       "1    1.808955 -0.343013  1.465924  ... -1.809128  0.381091  0.497534   \n",
       "2   -2.480777  0.506680  0.852822  ...  0.091664  0.655664 -0.191965   \n",
       "3    0.098418 -0.677591 -1.276767  ... -0.280935 -0.523440 -0.230028   \n",
       "4   -0.271543  0.229179  0.089760  ... -0.728898 -0.124473 -0.842829   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995 -0.952754 -0.825043  0.508768  ...  1.263616  1.249821  0.778397   \n",
       "996  0.214231  0.032185 -2.389823  ... -0.334054  0.202016 -0.348515   \n",
       "997 -0.298138  1.466069 -1.368111  ...  0.424773  0.706320 -0.098820   \n",
       "998 -0.338317 -1.390537 -0.565669  ...  1.377252 -0.221610  0.200315   \n",
       "999  1.013718 -1.256276 -0.398812  ... -2.903293  1.517092  0.065016   \n",
       "\n",
       "          X44       X45       X46       X47       X48       X49       X50  \n",
       "0    1.372374 -0.212618 -1.368046 -1.740719  0.925212  0.123907 -1.020763  \n",
       "1    0.632532 -1.429868 -2.092106  0.499216  1.026407 -0.763639 -0.405548  \n",
       "2    1.194055  0.326962  0.399151  0.723069  0.939017 -1.132469  0.212292  \n",
       "3    1.939640 -0.429125  0.701319 -1.008541  1.055334 -0.782659  0.749695  \n",
       "4   -0.132558 -0.236122 -0.751535  0.191009  0.007180 -0.350858  0.384321  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.360644  1.407061  1.214776  0.113185 -1.092583 -0.705830 -0.492108  \n",
       "996  1.547892 -0.924954 -0.393573  0.810303 -0.265939  0.290818  0.370616  \n",
       "997 -0.281987  0.727978  0.530025  0.860666  1.001294  0.159725  0.409749  \n",
       "998  0.616052  1.238358  0.175405  1.963846 -1.160791 -0.170900 -0.414812  \n",
       "999 -1.859139 -0.232359  0.162459 -0.193444 -1.936912  0.381345  0.132111  \n",
       "\n",
       "[1000 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data set\n",
    "data = pd.read_csv('PCA_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4542fa-ef84-4fa1-9d7d-5ac28c954eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data and designating the training and the test sample\n",
    "train_sample = data[:500]\n",
    "test_sample = data[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6cafa-0d33-4f97-b27e-0bcf6075f0fc",
   "metadata": {},
   "source": [
    "#### b) Compute the first 10 principal component vectors and the corresponding scores Z∗1 , . . . , Z∗ 10 for (X1, X2, . . . , X50). For simplicity, you can use the whole data set for this (both the training sample as well as the test sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748a9383-03f1-4b6b-93b7-5ea46a501ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying PCA and calculating the principal components as X_pca\n",
    "pca = PCA()\n",
    "\n",
    "# Calculating all the principal component scores\n",
    "X_pca = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522a3674-e5df-41b9-81ec-2fec75c91466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing the first 10 principal component vectors\n",
    "pca_vectors = pca.components_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f569c0-3054-44e5-9371-73d64f754426",
   "metadata": {},
   "source": [
    "#### c) Estimate an OLS regression of Y on a constant and X1, . . . , X50 over the training sample. Estimate OLS regressions of Y on a constant and Z∗1, . . . , Z∗k over the training sample for k = 1, 5, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e068c6b-089a-4ffd-b154-cc338ac76e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming that Y is the target variable, we are dropping it\n",
    "X_train = train_sample.drop('Y', axis = 1)\n",
    "X_test = test_sample.drop('Y', axis = 1)\n",
    "\n",
    "# Setting Y as a new variable\n",
    "y_train = train_sample['Y']\n",
    "y_test = test_sample['Y']\n",
    "\n",
    "# We are fitting it on the training sets\n",
    "ols_on_X = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b286cb96-f0e0-4678-8879-b636f465086f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS regression without applying PCA:\n",
      " \n",
      "The Intercept is 0.9368192754190612.\n",
      "The MSPE is 23.528930608001616.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 1.\n",
      "The coefficients are: [0.01687943].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 1 value is 15.026864642641463.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 5.\n",
      "The coefficients are: [ 0.01687943  0.04055752 -0.40126178 -0.04866477 -0.9367122 ].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 5 value is 17.429419813414164.\n",
      "--------------------------------------------------\n",
      " \n",
      "k = 10.\n",
      "The coefficients are: [ 0.01687943  0.04055752 -0.40126178 -0.04866477 -0.9367122   0.52798791\n",
      " -0.53136266 -0.08113065 -0.6672775  -0.62775569].\n",
      "The Intercept is 1.0331068182440002.\n",
      "The MSPE for k = 10 value is 20.441690618275057.\n",
      "--------------------------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Iniating an empty list for the results\n",
    "results = []\n",
    "\n",
    "# Predicting without the PCA and calculating the MSPE\n",
    "prediction_ols = ols_on_X.predict(X_train)\n",
    "mspe_ols = np.mean((prediction_ols - y_test)**2)\n",
    "\n",
    "# Appending it to the results table\n",
    "results.append({'Model': f\"OLS\", \"MSPE\" : mspe_ols})\n",
    "\n",
    "# Printing the results\n",
    "print('OLS regression without applying PCA:')\n",
    "print(' ')\n",
    "print(f'The Intercept is {ols_on_X.intercept_}.')\n",
    "print(f'The MSPE is {mspe_ols}.')\n",
    "print('-'*50)\n",
    "print(' ')\n",
    "\n",
    "# Defining a list for the k values\n",
    "k_to_try = [1, 5, 10]\n",
    "\n",
    "# Calculating all the principal component scores\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Defining a for loop for the k values\n",
    "for k in k_to_try:\n",
    "    \n",
    "    # Extracting the first k components\n",
    "    X_train_pca_k = X_train_pca[:, :k]\n",
    "    # Fitting the model\n",
    "    ols_on_pca = LinearRegression().fit(X_train_pca_k, y_train)\n",
    "    \n",
    "    # Calculating the MSPE\n",
    "    prediction_pca = ols_on_pca.predict(X_train_pca_k)\n",
    "    mspe_pca = np.mean((prediction_pca - y_test)**2)\n",
    "    \n",
    "    # Appending the results to the list\n",
    "    results.append({'Model': f\"PCA (k = {k})\", \"MSPE\" : mspe_pca})\n",
    "    \n",
    "    # Printing the results\n",
    "    print(f'k = {k}.')\n",
    "    print(f'The coefficients are: {ols_on_pca.coef_}.')\n",
    "    print(f'The Intercept is {ols_on_pca.intercept_}.')\n",
    "    print(f'The MSPE for k = {k} value is {mspe_pca}.')\n",
    "    print('-'*50)\n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8ae4a-6df5-4fe5-9c6a-0cff778abbaf",
   "metadata": {},
   "source": [
    "#### d) Use the four models estimated under part c) the obtain predictions for the outcomes Yi in the test sample. Compute the mean squared prediction error for the four different predictions and report these numbers. You should get results similar to those on slide 22, but there will be some differences because the whole experiment is performed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce83a34-43f1-4903-9a03-41390555e956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>23.528931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA (k = 1)</td>\n",
       "      <td>15.026865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA (k = 5)</td>\n",
       "      <td>17.429420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA (k = 10)</td>\n",
       "      <td>20.441691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model       MSPE\n",
       "0           OLS  23.528931\n",
       "1   PCA (k = 1)  15.026865\n",
       "2   PCA (k = 5)  17.429420\n",
       "3  PCA (k = 10)  20.441691"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting all the MSPE values and putting them into a DataFrame\n",
    "mspe_values = pd.DataFrame(results)\n",
    "mspe_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55394ea7-ba9a-4c85-bf4f-60602db1b79f",
   "metadata": {},
   "source": [
    "#### e) Consider again the original ’Dense DGP’ table on slide 22, Lecture 3. Discuss and explain the MSPE patterns you see in the first column (Ntr = 75) and the last column (Ntr = 500)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ccf1a-a98f-49e3-9bc7-418866c53892",
   "metadata": {},
   "source": [
    "\\begin{array}{cccccc}\n",
    "& \\text{Ntr = 75} & \\text{Ntr = 150} & \\text{Ntr = 500} \\\\\n",
    "\\hline\n",
    "\\text{DENSE DGP} & \\text{MSPE} & \\text{MSPE} & \\text{MSPE} \\\\\n",
    "\\text{OLS} & 12.9 & 6.0 & 4.5 \\\\\n",
    "\\text{PCA (k=1)} & 14.9 & 14.7 & 14.6 \\\\\n",
    "\\text{PCA (k=5)} & 13.6 & 13.0 & 12.7 \\\\\n",
    "\\text{PCA (k=10)} & 9.3 & 8.5 & 8.0 \\\\\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac6cf6-922d-457a-aaa9-729760f652e8",
   "metadata": {},
   "source": [
    "---\n",
    "#### Analyzing by the sample size:\n",
    "##### N = 75:\n",
    "- When our n = 75, we can see that by applying higher k values in our PCA, (k$1$ = 1, k$2$ = 5, k$3$ = 10) our MSPE gradually decreases.\n",
    "- However compared to the OLS model, only k = 10 is enough to predict Y better than OLS.\n",
    "- The OLS model in this case is an overfit.\n",
    "- As the table displays, we can see that this sample obtained the highest MSPE values compared to bigger samples, suggesting that the model's predictive performance is poorer when trained on smaller datasets. This can be due to the limited amount of data available during model training, leading to less accurate estimation of relationships between the predictor variables and the target variable.\n",
    "\n",
    "##### N = 150:\n",
    "- As soon as we double our sample size, we can see a notable improvement in the OLS model. The OLS here overperforms all the other regressions with PCA values. \n",
    "-  When comparing each model to their equivalent with a sample size of n = 75, all models show improved MSPE values. This suggests that increasing the sample size from n = 75 has a positive influence on the predictive performance of the models. \n",
    "- It's important to note that similar to n = 75, the MSPE is decreasing as we increase the number of principal components, capturing additional variance in the data. Furthermore, we are retaining more information from the original features as more variance is explained by the principal components. With more data available for the model training, the models can capture underlying patterns and relationships better in the data. \n",
    "##### N = 500:\n",
    "- When the sample size = 500, the OLS's MPSE is lower than the models with PCA. That is because when we apply PCA on large samples, we compress the information too much and hence, we are losing information. This loss of information negatively impacts the MSPE of the models.\n",
    "- This case represents well that while the compression can reduce the dimensionality of the data and potentially improve computational efficiency, it also inevitably leads to some loss of information.\n",
    "- Big Data and ML methods are useful when the x predictor number is considerably large compared to the sample size.\n",
    "\n",
    "#### Analyzing by the models:\n",
    "- **OLS:** As the sample size increases, the performance of the OLS model improves. We can observe a notable improvement in MSPE when doubling the sample size from n = 57 to 500. The MSPE decreases by half. However, when we set the sample size to 500, the improvement in MSPE is less pronounced compared to the previous increase in the sample size.\n",
    "- **PCA = 1:** When the number of principal components is 1 (k = 1), we can see a smaller but gradual improvement in the MSPE as the sample size increases, regardless of the volume of the change. This smaller improvement can be due to the limitations of dimensionality reduction.\n",
    "- **PCA = 5:** When k = 5, our MSPE values are lower compared to k = 1. Similarly to the other PCA model, the MSPE decreases as we increase the sample size.\n",
    "- **PCA = 10:** We obtain the lowest MSPE values among PCA models when the number of principal components is the highest. As expected, the MSPE values reduce as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e0a1b-c290-4580-acf8-555cdbed0217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
